{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> This notebook requires at least 512 GB of SHM to run. While launching the dev pod on DGX Cloud Lepton, enter <code>512</code> in the <b>Advanced Configuration > Shared Memory</b> field.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT with NeMo Framework\n",
    "This notebook demonstrates how to use NeMo Framework to run supervised fine-tuning (SFT) to add reasoning capabilities to an LLM. The example first pre-processes the [OpenMathReasoning](https://huggingface.co/datasets/nvidia/OpenMathReasoning) dataset which contains millions of sample math problems with chain-of-thought (COT) sequences. Using the prepared dataset, it downloads and fine-tunes the Qwen2.5-Math-1.5B base model to instruct it to follow the chain-of-thought pattern, resulting in more accurate responses.\n",
    "\n",
    "### Requirements\n",
    "The notebook requires the following to run successfully:\n",
    "* 8x GPUs with at least 80 GB of GPU memory each\n",
    "* 512 GB of SHM attached to the container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Job Settings\n",
    "Let's specify the high-level settings that will be used for fine-tuning the model. The values can be changed if needed, but the notebook is designed to run with the default values shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"Qwen/Qwen2.5-Math-1.5B\"  # Base model we will fine-tune\n",
    "LOG_DIR=\"/workspace/qwen-sft\"  # Directory to store the logs and checkpoints\n",
    "JOB_NAME=\"qwen-open-math-reasoning\"  # Name of the job\n",
    "DATASET_NAME = \"nvidia/OpenMathReasoning\"  # Math reasoning dataset to fine-tune against\n",
    "DATA_DIRECTORY = \"/workspace/data/openmath_reasoning\"  # Directory to store the dataset\n",
    "DATASET_SPLIT = \"cot\"  # Which dataset split to use\n",
    "GPUS_PER_NODE = 8  # Number of GPUs per node to use for fine-tuning\n",
    "TENSOR_PARALLELISM = 2  # Tensor parallelism level to split the model across GPUs\n",
    "CONTEXT_PARALLELISM = 1  # Amount to split the sequence context across GPUs\n",
    "SEQ_LENGTH = 32768  # Total number of input+output tokens to fine-tune\n",
    "GLOBAL_BATCH_SIZE = 4  # Total number of tokens to process in each step\n",
    "MICRO_BATCH_SIZE = 1  # Number of tokens to process in each step\n",
    "MAX_STEPS = 8000  # Maximum number of steps to fine-tune for\n",
    "LR = 3e-4  # Maximum learning rate during fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases Integration\n",
    "NeMo Framework supports Weights and Biases (W&B) for tracking model training metrics. To track your training with W&B, add your API key in the EV below and specify the project and job names. Leave the `WANDB_API_KEY` variable blank to skip W&B tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_API_KEY = \"\"  # Optionally add your W&B API key here if desired. If kept blank, W&B will not be used.\n",
    "WANDB_PROJECT = \"nemo-sft\"  # Project to save the job under in W&B\n",
    "WANDB_JOB_NAME = \"openmath-reasoning\"  # Name of the specific job in W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Base Model\n",
    "First, we need to download the base model from Hugging Face which we will be fine-tuning. This step downloads the Qwen2.5-Math-1.5B model from Hugging Face and converts it to the NeMo format which allows it to be fine-tuned directly with NeMo Framework.\n",
    "\n",
    "This cell uses [NeMo-Run](https://github.com/nvidia-nemo/run) to launch a job inside the container in a background process. It will take a couple of minutes to download and convert the model depending on your network connection. The cell will output the following when successful:\n",
    "\n",
    "```\n",
    "Converted Qwen model to Nemo, model saved to /root/.cache/nemo/models/Qwen/Qwen2.5-Math-1.5B\n",
    "```\n",
    "\n",
    "To use a different model as a base, change the `BASE_MODEL` setting above and update the `model=llm.qwen25_1p5b.model()` line with the link to the corresponding model in NeMo Framework. See [this link](https://github.com/NVIDIA-NeMo/NeMo/tree/main/nemo/collections/llm/recipes) for the list of models supported by NeMo Framework and for the corresponding model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nemo_run as run\n",
    "from nemo.collections import llm\n",
    "\n",
    "def configure_checkpoint_conversion():\n",
    "    return run.Partial(\n",
    "        llm.import_ckpt,\n",
    "        model=llm.qwen25_1p5b.model(),\n",
    "        source=f\"hf://{BASE_MODEL}\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "import_ckpt = configure_checkpoint_conversion()\n",
    "local_executor = run.LocalExecutor()\n",
    "\n",
    "run.run(import_ckpt, executor=local_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "We need to download and prepare a dataset to feed the model during fine-tuning. NeMo Framework expects a training and validation file in JSONL format. The default expected keys are `input` for the input prompts, and `output` for the generated responses.\n",
    "\n",
    "The following cell first loads the nvidia/OpenMathReasoning dataset from Hugging Face, iterates through the `cot` dataset split, rewrites the `problem` column to `input`, and the `generated_solution` column to `output`, and saves it to JSONL files in the container.\n",
    "\n",
    "To use a different dataset, replace the `DATASET_NAME` field with the repo ID of a Hugging Face dataset, and modify the `input` and `output` columns as necessary to match what's used in your dataset.\n",
    "\n",
    "By default, the dataset will be saved to the `DATA_DIRECTORY` of `/workspace/data/openmath_reasoning`.\n",
    "\n",
    "This step takes approximately 15 minutes to complete depending on your network speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "def prepare_dataset():\n",
    "    dataset = load_dataset(DATASET_NAME)\n",
    "    train_file_path = os.path.join(DATA_DIRECTORY, \"training.jsonl\")\n",
    "    val_file_path  = os.path.join(DATA_DIRECTORY, \"validation.jsonl\")\n",
    "\n",
    "    # Check if the dataset has already been prepared\n",
    "    if os.path.exists(train_file_path) and os.path.exists(val_file_path):\n",
    "        print(\"Dataset already prepared. Skipping...\")\n",
    "        return\n",
    "\n",
    "    with open(train_file_path, \"w\") as train_file, open(val_file_path, \"w\") as val_file:\n",
    "        for train_counter, line in enumerate(dataset[DATASET_SPLIT]):\n",
    "            # Rename the columns to match the expected keys\n",
    "            desired_data = {\n",
    "                \"input\": line[\"problem\"],\n",
    "                \"output\": line[\"generated_solution\"],\n",
    "            }\n",
    "\n",
    "            # Include 100 validation examples\n",
    "            if train_counter < 100:\n",
    "                json.dump(desired_data, val_file)\n",
    "                val_file.write(\"\\n\")\n",
    "            # Include one million training examples from the dataset\n",
    "            elif train_counter < 1000000:\n",
    "                json.dump(desired_data, train_file)\n",
    "                train_file.write(\"\\n\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True)\n",
    "prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Dataset\n",
    "After preparing the dataset, check the first line of each file to see the output format and ensure it matches the expected format. The output should look similar to the following (truncated for readability).\n",
    "\n",
    "training.jsonl:\n",
    "```\n",
    "{\"input\": \"A balance scale sits on a teacher's table, currently tipped to the right. <truncated>\", \"output\": \"<think>\\nOkay, let's try to tackle this problem. Hmm, so we have a balance scale that's tipped to the right initially. <truncated> **Final Answer:**\\n   - The sum of \\\\( f(S) \\\\) for all possible non-empty subsets \\\\( S \\\\) of pupils is:\\n     \\\\[\\n     \\\\boxed{2^{n-1} (R - L)}\\n     \\\\]\\n\\nThis is the final answer, where \\\\( R \\\\) is the total weight on the right side initially, and \\\\( L \\\\) is the total weight on the left side initially.\"}\n",
    "```\n",
    "\n",
    "validation.jsonl:\n",
    "```\n",
    "{\"input\": \"Given a group of \\\\( N \\\\) balls consisting of \\\\( C \\\\) colors, where <truncated>\", \"output\": \"<think>\\nOkay, so I need to find the probability that when I pick A balls out of N, where there are C different colors, the number of each color I pick is exactly a1, a2, ..., aC. Hmm, let's think about how to approach this.\\n\\nFirst, probability problems often involve combinations. The general formula for probability is the number of favorable outcomes divided by the total number of possible outcomes. <truncated> Final Solution:\\nThe probability that when \\\\( A \\\\) balls are randomly picked from \\\\( N \\\\) balls, the picked balls consist of \\\\( a_1, a_2, \\\\ldots, a_C \\\\) balls of each color is given by:\\n\\\\[\\n\\\\boxed{\\\\frac{\\\\prod_{i=1}^{C} \\\\binom{n_i}{a_i}}{\\\\binom{N}{A}}}\\n\\\\]\\n\\nThis solution is derived from the multivariate hypergeometric distribution, where the combinations \\\\( \\\\binom{n_i}{a_i} \\\\) account for the ways to choose \\\\( a_i \\\\) balls from \\\\( n_i \\\\) balls of color \\\\( i \\\\), and the denominator \\\\( \\\\binom{N}{A} \\\\) accounts for the total ways to choose \\\\( A \\\\) balls from \\\\( N \\\\) balls.\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 data/openmath_reasoning/*jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Module\n",
    "Now that the dataset has been prepared, we need to tell NeMo Framework how to load it and configure some hyperparameters including the tokenizer, maximum sequence length, and global and micro batch sizes. Let's look a bit deeper at some of these settings.\n",
    "\n",
    "* seq_length: This is the maximum number of input+output tokens that will be processed by the model during fine-tuning. Any lines in the dataset that have input+output tokens that is longer than the seq_length will be truncated. Longer sequence lengths allow for longer input and output responses, but require additional memory during fine-tuning and deployment.\n",
    "* global_batch_size: This is the amount of sequences that are processed during every step. In general, higher batch sizes allow greater throughput at the cost of potentially running out of GPU memory. If you experience CUDA OOM errors, try lowering the `GLOBAL_BATCH_SIZE`. It needs to be a power-of-2 value (ie. 2, 4, 8, ...).\n",
    "* micro_batch_size: This is the amount to sub-divide sequences on GPUs during every step. In general, higher batch sizes allow greater throughput at the cost of potentially running out of GPU memory. If you expeience CUDA OOM errors, try lowering the `MICRO_BATCH_SIZE`. It needs to be less than or equal to `GLOBAL_BATCH_SIZE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.common.tokenizers import AutoTokenizer\n",
    "from nemo.collections.llm.gpt.data.fine_tuning import FineTuningDataModule\n",
    "\n",
    "def data_module() -> run.Config:\n",
    "    tokenizer = run.Config(AutoTokenizer, pretrained_model_name=BASE_MODEL)\n",
    "\n",
    "    return run.Config(\n",
    "        FineTuningDataModule,\n",
    "        dataset_root=DATA_DIRECTORY,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        global_batch_size=GLOBAL_BATCH_SIZE,\n",
    "        micro_batch_size=MICRO_BATCH_SIZE,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Checkpoint Resumption\n",
    "We need to specify the model checkpoint to fine-tune. This indicates the base model that should be updated based on the fine-tuning dataset. This cell tells NeMo Framework to load the model that was downloaded from Hugging Face and converted to the NeMo format earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo import lightning as nl\n",
    "\n",
    "def checkpoint_resumption() -> run.Config:\n",
    "    return run.Config(\n",
    "        nl.AutoResume,\n",
    "        restore_config=run.Config(nl.RestoreConfig,\n",
    "            path=f\"nemo://{BASE_MODEL}\"\n",
    "        ),\n",
    "        resume_if_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logger\n",
    "Next, the logger needs to be configured to indicate where checkpoints and logs should be saved. All checkpoints will be saved in the `{LOG_DIR}/{JOB_NAME}/checkpoints` directory, such as `/workspace/qwen-sft/qwen-open-math-reasoning/checkpoints`.\n",
    "\n",
    "If a W&B key was added at the beginning of the notebook, the W&B logger will also be added and metrics will automatically be uploaded to W&B servers during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.llm.recipes.log.default import default_log, wandb_logger\n",
    "\n",
    "def logger(log_dir: str, name: str):\n",
    "    if WANDB_API_KEY != \"\":\n",
    "        wandb = wandb_logger(\n",
    "            project=WANDB_PROJECT,\n",
    "            name=WANDB_JOB_NAME,\n",
    "        )\n",
    "        return default_log(dir=log_dir, name=name, wandb_logger=wandb)\n",
    "    else:\n",
    "        return default_log(dir=log_dir, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Trainer\n",
    "We now specify the high-level settings for the trainer, such as the number of nodes and GPUs to fine-tune with. Additionally, specifying the `CONTEXT_PARALLELISM` and `TENSOR_PARALLELISM` sizes to spread the context and model weights across GPUs to reduce memory usage. In general, if training throws CUDA OOM errors, try doubling some of the parallelism sizes to spread the reduce the memory requirements for each GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.llm.recipes.qwen2 import qwen2_trainer\n",
    "\n",
    "def trainer(nodes: int = 1, gpus_per_node: int = 8):\n",
    "    return qwen2_trainer(\n",
    "        num_nodes=nodes,\n",
    "        num_gpus_per_node=gpus_per_node,\n",
    "        max_steps=MAX_STEPS,\n",
    "        context_parallelism=CONTEXT_PARALLELISM,\n",
    "        tensor_parallelism=TENSOR_PARALLELISM,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Optimizer\n",
    "We now setup the optimizer for fine-tuning. We will use the standard Adam optimizer with cosine annealing. Specify the maximum learning rate and warmup steps for the learning rate scheduler to change over time. Note that this workflow hasn't been compared against different learning rates, so it is possible different values could yield higher quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.llm.recipes.optim.adam import distributed_fused_adam_with_cosine_annealing\n",
    "\n",
    "def optimizer():\n",
    "    return distributed_fused_adam_with_cosine_annealing(max_lr=LR, warmup_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Fine-Tuning Recipe\n",
    "Finally, we pull everything together to define the recipe for fine-tuning the model. This uses all of the settings we specified in the previous cells and creates an object that describes the complete setup for the fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_recipe(nodes: int = 1, gpus_per_node: int = 8, log_dir=None, name=\"nemo\"):\n",
    "    recipe = run.Partial(\n",
    "        llm.finetune,\n",
    "        model=llm.qwen25_1p5b.model(),\n",
    "        data=data_module(),\n",
    "        trainer=trainer(nodes, gpus_per_node),\n",
    "        log=logger(log_dir, name),\n",
    "        optim=optimizer(),\n",
    "    )\n",
    "\n",
    "    recipe.model.config.calculate_per_token_loss = True\n",
    "    recipe.trainer.strategy.ckpt_load_strictness = False\n",
    "    recipe.trainer.val_check_interval = 100\n",
    "\n",
    "    recipe.resume = checkpoint_resumption()\n",
    "\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Training\n",
    "With the recipe defined, we can now launch the fine-tuning job. Similar to the model conversion cell above, this step uses NeMo-Run to launch the fine-tuning job with NeMo Framework inside the container. By default, this runs with 8 GPUs on a single node.\n",
    "\n",
    "Depending on the settings used, this step will take several hours to run on 8x H100 GPUs. There will be a lot of output during the process, including some warnings that can be safely ignored. As the fine-tuning process begins, you will see several lines that will look similar to the following:\n",
    "\n",
    "```\n",
    "i.finetune/0 [default0]:Training epoch 0, iteration 0/7999 | lr: 2.727e-05 | global_batch_size: 4 | global_step: 0 | reduced_train_loss: 1.561\n",
    "i.finetune/0 [default0]:Training epoch 0, iteration 1/7999 | lr: 5.455e-05 | global_batch_size: 4 | global_step: 1 | reduced_train_loss: 1.621 | consumed_samples: 8\n",
    "i.finetune/0 [default0]:Training epoch 0, iteration 2/7999 | lr: 8.182e-05 | global_batch_size: 4 | global_step: 2 | reduced_train_loss: 0.9908 | consumed_samples: 12\n",
    "i.finetune/0 [default0]:Training epoch 0, iteration 3/7999 | lr: 0.0001091 | global_batch_size: 4 | global_step: 3 | reduced_train_loss: 1.041 | consumed_samples: 16\n",
    "i.finetune/0 [default0]:Training epoch 0, iteration 4/7999 | lr: 0.0001364 | global_batch_size: 4 | global_step: 4 | reduced_train_loss: 0.7781 | consumed_samples: 20\n",
    "...\n",
    "```\n",
    "\n",
    "This output displays the following information in order:\n",
    "* epoch: The current epoch in the fine-tuning pass. This will very likely be `0` for the entire process.\n",
    "* iteration: This is the current step the process is on including the maximum number of steps for training.\n",
    "* lr: This is the current learning rate for the indicated step. This will start off small, quickly jump up, then decay following the cosine annealing learning rate scheduler.\n",
    "* global_batch_size: This is a static number indicated the batch size used for training.\n",
    "* global_step: This is the current step that has been completed.\n",
    "* reduced_train_loss: This is the current `train_loss` value that was calculated after the last step.\n",
    "* consumed_samples: This shows how many sequences have been processed so far. To find the number of tokens processed, multiply this value by `SEQ_LENGTH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def local_executor_torchrun(devices: int = 8) -> run.LocalExecutor:\n",
    "    env_vars = {}\n",
    "\n",
    "    if WANDB_API_KEY != \"\":\n",
    "        env_vars[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "    return run.LocalExecutor(ntasks_per_node=devices, launcher=\"torchrun\", env_vars=env_vars)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    recipe = configure_recipe(\n",
    "        nodes=1,\n",
    "        gpus_per_node=GPUS_PER_NODE,\n",
    "        log_dir=LOG_DIR,\n",
    "        name=JOB_NAME\n",
    "    )\n",
    "    run.run(recipe, executor=local_executor_torchrun(devices=GPUS_PER_NODE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Checkpoint\n",
    "Once training finishes, your final checkpoint will be saved in the specified directory. This will default to `{LOG_DIR}/{JOB_NAME}/checkpoints` or `/workspace/qwen-sft/qwen-open-math-reasoning/checkpoints`. The final checkpoint will end with `-last` in the directory name. The cell below lists the final checkpoint which can be used for downstream tasks like evaluation and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name \"*-last\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Congratulations, you have successfully fine-tuned an LLM using NeMo Framework! The fine-tuned model will have additional math reasoning capabilities which allow it to think through challenging math problems and should provide higher accuracy scores in math benchmarks.\n",
    "\n",
    "From here, you can deploy the final checkpoint as an Endpoint on DGX Cloud Lepton, allowing inference requests to be sent directly to the model. For more information on deploying models as Endpoints, [read here](https://docs.nvidia.com/dgx-cloud/lepton/features/endpoint/create-from-container-image/).\n",
    "\n",
    "Additionally, you can evaluate the fine-tuned model using various evaluation harnesses including [EleutherAI's lm-evaluation-harness](https://github.com/eleutherAI/lm-evaluation-harness/)."
   ]
  }
 ],
 "metadata": {
  "container_image": "nvcr.io/nvidia/nemo:25.07",
  "description": "Add math reasoning capabilities to Qwen2.5-1.5B by running supervised fine-tuning (SFT) with NeMo Framework",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "title": "SFT using NeMo Framework"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
