{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLUX NIMs Interactive Lab\n",
    "\n",
    "Welcome to hands-on exploration of NVIDIA NIMs with FLUX image generation models!\n",
    "\n",
    "## What are NVIDIA NIMs?\n",
    "NVIDIA NIMs (NVIDIA Inference Microservices) are optimized containers that serve AI models with maximum performance. Instead of downloading large model files locally, you connect to pre-optimized endpoints that handle inference with advanced optimizations like quantization (FP8/FP4) and TensorRT acceleration.\n",
    "\n",
    "## What You'll Do:\n",
    "- üöÄ Deploy FLUX.1-dev NIM to the cloud using Lepton\n",
    "- üé® Generate stunning images from text prompts\n",
    "- üîß Experiment with different parameters (steps, seed, prompts)\n",
    "- ‚úÇÔ∏è Edit images with natural language using FLUX Kontext\n",
    "- üí° Learn production-ready AI deployment workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "### Background: Understanding the Python Environment\n",
    "\n",
    "This step prepares your Python environment with the necessary libraries for interacting with NVIDIA NIMs and processing images. Each library serves a specific purpose:\n",
    "\n",
    "**Core Libraries Explained:**\n",
    "- **`ipywidgets`**: Creates interactive UI elements (dropdowns, sliders, buttons) within Jupyter notebooks\n",
    "- **`requests`**: Handles HTTP communication with NIM API endpoints\n",
    "- **`pillow` (PIL)**: Python Imaging Library for image processing, conversion, and manipulation\n",
    "- **`numpy`**: Numerical computing library used for efficient array operations on image data\n",
    "- **`matplotlib`**: Plotting library for displaying images and creating visualizations\n",
    "\n",
    "**Why These Libraries?**\n",
    "- **Interactive Experience**: ipywidgets transforms a static notebook into a dynamic interface\n",
    "- **API Communication**: requests provides reliable HTTP client functionality for NIM endpoints\n",
    "- **Image Processing**: PIL and numpy handle image format conversions (base64 ‚Üî binary ‚Üî display)\n",
    "- **Visualization**: matplotlib renders images inline and creates performance charts\n",
    "\n",
    "**What the Code Does:**\n",
    "1. **Package Installation**: `!pip install` ensures all required packages are available\n",
    "2. **Import Statements**: Load all necessary modules into the Python namespace\n",
    "3. **Validation**: Print confirmation that environment setup completed successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for NVIDIA NIM interaction and image processing\n",
    "# Install node.js v20 or newer\n",
    "# Install and setup Node.js using nvm\n",
    "#!curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash\n",
    "#!. \"$HOME/.nvm/nvm.sh\" && nvm install --lts\n",
    "#!. \"$HOME/.nvm/nvm.sh\" && nvm use --lts\n",
    "#print(\"‚úÖ Node.js installation complete\")\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install jupyter jupyterlab ipywidgets requests pillow numpy matplotlib pyyaml leptonai\n",
    "\n",
    "# Fix widget extensions (run if widgets don't display)\n",
    "!jupyter nbextension install --py --sys-prefix widgetsnbextension\n",
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "# Import all required libraries for the notebook\n",
    "import os          # File system operations\n",
    "import sys         # System-specific parameters and functions\n",
    "import json        # JSON data handling for API responses\n",
    "import time        # Timing operations for performance measurement\n",
    "import base64      # Image encoding/decoding for API transmission\n",
    "import io          # Input/output operations for image handling\n",
    "import subprocess  # Process execution for CLI operations\n",
    "import requests    # HTTP client for NIM API communication\n",
    "import numpy as np # Numerical operations on image arrays\n",
    "from datetime import datetime  # Date/time operations\n",
    "\n",
    "# Jupyter and visualization imports\n",
    "import ipywidgets as widgets  # Interactive UI components\n",
    "from IPython.display import display, HTML, clear_output, Image as IPImage\n",
    "\n",
    "# Image processing imports\n",
    "from PIL import Image as PILImage  # Image processing and manipulation\n",
    "import matplotlib.pyplot as plt   # Plotting and image visualization\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(\"üìö All libraries imported:\")\n",
    "print(\"  ‚Ä¢ ipywidgets: Interactive UI components\")\n",
    "print(\"  ‚Ä¢ requests: HTTP communication with NIMs\")\n",
    "print(\"  ‚Ä¢ PIL: Image processing and conversion\")\n",
    "print(\"  ‚Ä¢ matplotlib: Image display and visualization\")\n",
    "print(\"  ‚Ä¢ numpy: Numerical operations on images\")\n",
    "print(\"  ‚Ä¢ leptonai: Lepton CLI for endpoint deployment\")\n",
    "print(\"  ‚Ä¢ subprocess: CLI command execution\")\n",
    "print(\"\\nüí° If widgets don't display, restart kernel and re-run this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: NIM Endpoint Configuration\n",
    "\n",
    "### Background: Understanding NVIDIA NIMs Architecture\n",
    "\n",
    "**What are NVIDIA NIMs?**\n",
    "NVIDIA NIMs (NVIDIA Inference Microservices) are containerized AI model serving solutions that provide:\n",
    "\n",
    "- **Optimized Inference**: Models are pre-quantized and optimized with TensorRT for maximum performance\n",
    "- **Standardized APIs**: Consistent REST API interface across all NIM containers\n",
    "- **Production Ready**: Built-in scaling, monitoring, and deployment capabilities\n",
    "- **Hardware Acceleration**: Automatic GPU utilization and memory optimization\n",
    "\n",
    "**NIM vs Traditional Model Hosting:**\n",
    "| Traditional Approach | NVIDIA NIMs |\n",
    "|---------------------|-------------|\n",
    "| Manual model optimization | Pre-optimized with TensorRT |\n",
    "| Custom API development | Standardized REST API |\n",
    "| Complex deployment | Docker container deployment |\n",
    "| Variable performance | Consistent, optimized performance |\n",
    "\n",
    "**Deployment Options:**\n",
    "\n",
    "We'll be using **Custom NIM Endpoints** deployed to cloud platforms:\n",
    "   - Deploy to cloud platforms (Lepton, AWS, GCP, Azure)\n",
    "   - Production-ready scaling\n",
    "   - Remote GPU resources\n",
    "   - Custom domain/URL access\n",
    "\n",
    "**What the Configuration Code Does:**\n",
    "- **Text Input Widget**: Allows entry of custom NIM endpoint URLs\n",
    "- **Password Widget**: Secure input for NGC API keys (required for container access)\n",
    "- **Display Logic**: Shows interactive UI elements for endpoint configuration\n",
    "\n",
    "**NGC API Key Purpose:**\n",
    "The NGC (NVIDIA GPU Cloud) API key is required to:\n",
    "- Pull NIM containers from NVIDIA's registry\n",
    "- Authenticate with deployed NIM endpoints\n",
    "- Access NVIDIA's optimized model containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Lepton CLI Setup & Authentication\n",
    "\n",
    "### One-Click Lepton Setup\n",
    "\n",
    "This cell installs the Lepton CLI and handles authentication, making the notebook completely self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lepton CLI Installation and Manual Authentication\n",
    "# Expected time: 2-3 minutes for installation + manual login\n",
    "\n",
    "# Create widgets for NGC API key (still needed for NIM containers)\n",
    "ngc_api_key_widget = widgets.Password(\n",
    "    placeholder='Enter your NGC API key',\n",
    "    description='NGC API Key:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "setup_output = widgets.Output()\n",
    "\n",
    "def test_lepton_command(cmd_path):\n",
    "    \"\"\"Test if a lepton command works\"\"\"\n",
    "    try:\n",
    "        if isinstance(cmd_path, list):\n",
    "            result = subprocess.run(cmd_path + ['--version'], capture_output=True, text=True, timeout=10)\n",
    "        else:\n",
    "            result = subprocess.run([cmd_path, '--version'], capture_output=True, text=True, timeout=10)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout.strip()\n",
    "        else:\n",
    "            return False, f\"Command failed: {result.stderr}\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error testing command: {str(e)}\"\n",
    "\n",
    "def install_lepton_cli():\n",
    "    \"\"\"Install Lepton CLI with comprehensive testing\"\"\"\n",
    "    \n",
    "    print(\"üîç Checking Python environment and pip...\")\n",
    "    print(f\"   üêç Python executable: {sys.executable}\")\n",
    "    print(f\"   üì¶ Python version: {sys.version}\")\n",
    "    \n",
    "    # Check pip version\n",
    "    try:\n",
    "        pip_result = subprocess.run([sys.executable, '-m', 'pip', '--version'], \n",
    "                                  capture_output=True, text=True, timeout=10)\n",
    "        if pip_result.returncode == 0:\n",
    "            print(f\"   üìã Pip version: {pip_result.stdout.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not check pip version: {e}\")\n",
    "    \n",
    "    print(\"\\nüîç Checking for existing Lepton CLI...\")\n",
    "    \n",
    "    # Test different command approaches based on official docs\n",
    "    test_commands = [\n",
    "        'lep',  # Official CLI command name\n",
    "        'lepton',  # Alternative name\n",
    "        f'{os.path.dirname(sys.executable)}/lep',\n",
    "        f'{os.path.dirname(sys.executable)}/lep.exe',\n",
    "        f'{os.path.dirname(sys.executable)}/Scripts/lep.exe',\n",
    "    ]\n",
    "    \n",
    "    for cmd in test_commands:\n",
    "        print(f\"   Testing: {cmd}\")\n",
    "        works, msg = test_lepton_command(cmd)\n",
    "        if works:\n",
    "            print(f\"   ‚úÖ Found working command: {cmd}\")\n",
    "            return True, f\"‚úÖ Lepton CLI found: {msg}\", cmd\n",
    "        else:\n",
    "            print(f\"   ‚ùå {cmd}: {msg}\")\n",
    "    \n",
    "    # Install leptonai package with force reinstall\n",
    "    try:\n",
    "        print(\"\\nüì¶ Installing leptonai package... (30-60 seconds)\")\n",
    "        print(\"   üîÑ Using --force-reinstall to ensure latest version\")\n",
    "        \n",
    "        # First, uninstall any existing version\n",
    "        print(\"   üóëÔ∏è  Uninstalling any existing leptonai...\")\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', 'leptonai', '-y'], \n",
    "                      capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        # Install latest version with force reinstall and no cache\n",
    "        result = subprocess.run([\n",
    "            sys.executable, '-m', 'pip', 'install', \n",
    "            '--upgrade', '--force-reinstall', '--no-cache-dir', \n",
    "            'leptonai'\n",
    "        ], capture_output=True, text=True, timeout=120)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            return False, f\"‚ùå pip install failed: {result.stderr}\", None\n",
    "        \n",
    "        print(\"‚úÖ Package installed successfully\")\n",
    "        \n",
    "        # Verify the installed version\n",
    "        try:\n",
    "            import leptonai\n",
    "            version = getattr(leptonai, '__version__', 'unknown')\n",
    "            print(f\"   üìã Installed leptonai version: {version}\")\n",
    "        except ImportError:\n",
    "            print(\"   ‚ö†Ô∏è  Could not import leptonai to check version\")\n",
    "        \n",
    "        # Test commands again after installation\n",
    "        print(\"üîç Testing commands after installation...\")\n",
    "        for cmd in test_commands:\n",
    "            print(f\"   Testing: {cmd}\")\n",
    "            works, msg = test_lepton_command(cmd)\n",
    "            if works:\n",
    "                print(f\"   ‚úÖ Working command found: {cmd}\")\n",
    "                return True, f\"‚úÖ Lepton CLI installed: {msg}\", cmd\n",
    "            else:\n",
    "                print(f\"   ‚ùå {cmd}: {msg}\")\n",
    "        \n",
    "        # Try to find lep executable in pip install location\n",
    "        print(\"üîç Searching for lep executable...\")\n",
    "        try:\n",
    "            # Get pip install location\n",
    "            pip_result = subprocess.run([sys.executable, '-m', 'pip', 'show', 'leptonai'], \n",
    "                                      capture_output=True, text=True)\n",
    "            if pip_result.returncode == 0:\n",
    "                for line in pip_result.stdout.split('\\n'):\n",
    "                    if line.startswith('Location:'):\n",
    "                        location = line.split(':', 1)[1].strip()\n",
    "                        print(f\"   Package location: {location}\")\n",
    "                        \n",
    "                        # Try to find bin directory and scripts\n",
    "                        possible_bins = [\n",
    "                            os.path.join(location, '..', 'bin', 'lep'),\n",
    "                            os.path.join(location, '..', '..', 'bin', 'lep'),\n",
    "                            os.path.join(location, '..', 'Scripts', 'lep.exe'),\n",
    "                            os.path.join(location, '..', '..', 'Scripts', 'lep.exe'),\n",
    "                            os.path.join(os.path.dirname(sys.executable), 'lep'),\n",
    "                            os.path.join(os.path.dirname(sys.executable), 'lep.exe'),\n",
    "                            os.path.join(os.path.dirname(sys.executable), 'Scripts', 'lep.exe'),\n",
    "                        ]\n",
    "                        \n",
    "                        for bin_path in possible_bins:\n",
    "                            normalized_path = os.path.normpath(bin_path)\n",
    "                            print(f\"   Checking: {normalized_path}\")\n",
    "                            if os.path.exists(normalized_path):\n",
    "                                works, msg = test_lepton_command(normalized_path)\n",
    "                                if works:\n",
    "                                    print(f\"   ‚úÖ Found working executable: {normalized_path}\")\n",
    "                                    return True, f\"‚úÖ Lepton CLI found: {msg}\", normalized_path\n",
    "                                else:\n",
    "                                    print(f\"   ‚ùå Executable found but not working: {msg}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error searching for executable: {e}\")\n",
    "        \n",
    "        return False, \"‚ùå Lepton CLI installed but no working command found. You may need to use Lepton web interface instead.\", None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"‚ùå Installation timed out\", None\n",
    "    except Exception as e:\n",
    "        return False, f\"‚ùå Installation error: {str(e)}\", None\n",
    "\n",
    "def manual_lepton_login(lepton_cmd):\n",
    "    \"\"\"Guide user through manual Lepton login process\"\"\"\n",
    "    \n",
    "    print(\"üîê Manual Lepton Authentication Required\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"The automated login approach has limitations.\")\n",
    "    print(\"Please follow these steps for manual authentication:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"STEP 1: Run the login command\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Command to run: {lepton_cmd} login\")\n",
    "    print()\n",
    "    \n",
    "    # Create a code cell that user can copy\n",
    "    login_command = f\"{lepton_cmd} login\"\n",
    "    print(\"üìã Copy and run this command in a new terminal:\")\n",
    "    print(f\"   {login_command}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"STEP 2: Follow the interactive prompts\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"1. Press Enter when prompted\")\n",
    "    print(\"2. A URL will be displayed - copy it\")\n",
    "    print(\"3. Open the URL in a new browser tab\")\n",
    "    print(\"4. Create a token in the Lepton dashboard\")\n",
    "    print(\"5. Copy the workspace:token from the second 'lep login' command output\")\n",
    "    print(\"6. Paste it back in the terminal and press Enter\")\n",
    "    print()\n",
    "    \n",
    "    print(\"STEP 3: Verify authentication\")\n",
    "    print(\"-\" * 35)\n",
    "    print(\"After successful login, run:\")\n",
    "    print(f\"   {lepton_cmd} workspace list\")\n",
    "    print()\n",
    "    print(\"You should see your workspace(s) listed.\")\n",
    "    print()\n",
    "    \n",
    "    print(\"STEP 4: Return to this notebook\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Once authenticated, you can proceed with NIM deployment.\")\n",
    "    print(\"The deployment cells will use your authenticated CLI session.\")\n",
    "    print()\n",
    "    \n",
    "    return True, \"Manual login instructions provided\"\n",
    "\n",
    "def setup_lepton_cli(button):\n",
    "    \"\"\"Complete Lepton CLI setup process with manual authentication\"\"\"\n",
    "    with setup_output:\n",
    "        setup_output.clear_output(wait=True)\n",
    "        \n",
    "        # Get NGC API key\n",
    "        ngc_key = ngc_api_key_widget.value.strip()\n",
    "        \n",
    "        print(\"üöÄ Setting up Lepton CLI environment...\")\n",
    "        print(\"‚è±Ô∏è  Expected time: 2-3 minutes\")\n",
    "        \n",
    "        # Validate NGC API key\n",
    "        if not ngc_key:\n",
    "            print(\"‚ùå Please enter your NGC API key\")\n",
    "            return\n",
    "            \n",
    "        print(f\"üìã NGC key length: {len(ngc_key)} characters\")\n",
    "        print()\n",
    "        \n",
    "        # Step 1: Install Lepton CLI\n",
    "        install_success, install_message, lepton_cmd = install_lepton_cli()\n",
    "        print(f\"\\n{install_message}\")\n",
    "        \n",
    "        if not install_success:\n",
    "            print(\"\\n‚ö†Ô∏è  CLI command not available\")\n",
    "            print(\"üí° You can use Lepton web interface for manual deployment:\")\n",
    "            print(\"   1. Go to https://dashboard.lepton.ai/\")\n",
    "            print(\"   2. Click 'Create Endpoint'\")\n",
    "            print(\"   3. Use these settings:\")\n",
    "            print(f\"      - Container: nvcr.io/nim/black-forest-labs/flux.1-dev:1.1.0\")\n",
    "            print(f\"      - Environment: NGC_API_KEY={ngc_key}\")\n",
    "            print(\"   4. Copy the endpoint URL for use in this notebook\")\n",
    "            \n",
    "            # Store NGC key for manual deployment\n",
    "            os.environ['NGC_API_KEY'] = ngc_key\n",
    "            print(\"\\n‚úÖ NGC API key configured for manual deployment\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîç Using Lepton command: {lepton_cmd}\")\n",
    "        \n",
    "        # Step 2: Guide user through manual authentication\n",
    "        auth_success, auth_message = manual_lepton_login(lepton_cmd)\n",
    "        print(f\"\\n{auth_message}\")\n",
    "        \n",
    "        if auth_success:\n",
    "            # Store configuration\n",
    "            os.environ['NGC_API_KEY'] = ngc_key\n",
    "            os.environ['LEPTON_CMD'] = str(lepton_cmd)  # Store command path for later use\n",
    "            \n",
    "            print(\"\\nüéâ Lepton CLI setup complete!\")\n",
    "            print(\"üí° After completing manual login, you can deploy NIM endpoints\")\n",
    "            print(\"üí° Available CLI commands after login:\")\n",
    "            print(\"   ‚Ä¢ lep deployment create - Create new deployments\")\n",
    "            print(\"   ‚Ä¢ lep deployment list - List existing deployments\")\n",
    "            print(\"   ‚Ä¢ lep workspace list - List workspaces\")\n",
    "            print()\n",
    "            print(\"‚ö†Ô∏è  Remember: You need to complete the manual login process\")\n",
    "            print(\"   in a terminal before proceeding with deployment.\")\n",
    "\n",
    "# Create setup interface\n",
    "print(\"üîß Lepton CLI Setup & Manual Authentication\")\n",
    "print(\"‚è±Ô∏è  Expected time: 2-3 minutes\")\n",
    "print(\"üìä Resources needed: Minimal (CLI installation + manual login)\")\n",
    "print(\"\\nüîë Required Credentials:\")\n",
    "\n",
    "display(ngc_api_key_widget)\n",
    "\n",
    "setup_button = widgets.Button(\n",
    "    description='üöÄ Setup Lepton CLI',\n",
    "    button_style='primary',\n",
    "    icon='wrench',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "setup_button.on_click(setup_lepton_cli)\n",
    "display(setup_button)\n",
    "display(setup_output)\n",
    "\n",
    "print(\"\\nüí° Where to get credentials:\")\n",
    "print(\"  ‚Ä¢ NGC API Key: https://ngc.nvidia.com/ ‚Üí Generate API Key\")\n",
    "print(\"\\nüìã What this does:\")\n",
    "print(\"  ‚Ä¢ Installs leptonai package with: pip install --upgrade --force-reinstall --no-cache-dir leptonai\")\n",
    "print(\"  ‚Ä¢ Uninstalls old versions first to ensure clean installation\")\n",
    "print(\"  ‚Ä¢ Finds working 'lep' command (official CLI)\")\n",
    "print(\"  ‚Ä¢ Provides manual login instructions\")\n",
    "print(\"  ‚Ä¢ Configures NGC API key for NIM deployment\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: Manual login required - automated authentication has limitations\")\n",
    "print(\"\\nüîÑ Installation Process:\")\n",
    "print(\"  ‚Ä¢ Uninstalls any existing leptonai package\")\n",
    "print(\"  ‚Ä¢ Installs latest version with force reinstall\")\n",
    "print(\"  ‚Ä¢ Skips pip cache to ensure fresh download\")\n",
    "print(\"  ‚Ä¢ Verifies installation and version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Deploy FLUX NIM Endpoints\n",
    "\n",
    "### Automated Endpoint Deployment\n",
    "\n",
    "Deploy FLUX NIMs as Lepton endpoints directly from the notebook. This creates production-ready API endpoints you can use immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLUX NIM Endpoint Deployment using Lepton CLI - CORRECTED VERSION\n",
    "# Expected time: 3-5 minutes per model (deployment + readiness check)\n",
    "# Resource requirements: 1 GPU (A10/A100) per endpoint\n",
    "\n",
    "# Deployment configuration widgets\n",
    "nim_model_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('FLUX.1 Dev - Text-to-Image Generation', 'flux.1-dev')\n",
    "    ],\n",
    "    value='flux.1-dev',\n",
    "    description='NIM Model:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "endpoint_name_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='my-flux-nim (auto-generated if empty)',\n",
    "    description='Endpoint Name:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Resource configuration with timing estimates\n",
    "resource_type_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('H200 GPU (Your DevPod) - Fastest deployment, ~2-3 min', 'gpu.1xh200'),\n",
    "        ('Small - A10 GPU (faster deployment, ~3-4 min)', 'gpu.a10'),\n",
    "        ('Medium - A100-40GB GPU (~4-5 min)', 'gpu.a100-40gb'),\n",
    "        ('Large - A100-80GB GPU (~5-6 min)', 'gpu.a100-80gb')\n",
    "    ],\n",
    "    value='gpu.1xh200',\n",
    "    description='Resources:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Deployment output\n",
    "deployment_output = widgets.Output()\n",
    "\n",
    "def discover_deployment_cli_syntax():\n",
    "    \"\"\"Discover the actual CLI syntax available for deployment commands\"\"\"\n",
    "    lepton_cmd = os.environ.get('LEPTON_CMD', 'lep')\n",
    "\n",
    "    commands_to_check = [\n",
    "        ([lepton_cmd, '--help'], \"Main commands\"),\n",
    "        ([lepton_cmd, 'deployment', '--help'], \"Deployment commands\"),\n",
    "        ([lepton_cmd, 'deployment', 'create', '--help'], \"Deployment create options\"),\n",
    "        ([lepton_cmd, 'deployment', 'list', '--help'], \"Deployment list options\"),\n",
    "        ([lepton_cmd, 'workspace', '--help'], \"Workspace commands\")\n",
    "    ]\n",
    "\n",
    "    discovered = {}\n",
    "\n",
    "    for cmd_parts, desc in commands_to_check:\n",
    "        try:\n",
    "            result = subprocess.run(cmd_parts, capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                discovered[desc] = result.stdout\n",
    "            else:\n",
    "                discovered[desc] = f\"Error: {result.stderr[:200]}\"\n",
    "        except Exception as e:\n",
    "            discovered[desc] = f\"Exception: {str(e)}\"\n",
    "\n",
    "    return discovered\n",
    "\n",
    "def check_lepton_version(lepton_cmd):\n",
    "    \"\"\"Check the version of Lepton CLI to understand available options\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run([lepton_cmd, '--version'], capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            version_info = result.stdout.strip()\n",
    "            print(f\"   üìã Lepton CLI version: {version_info}\")\n",
    "            \n",
    "            # Extract version number for compatibility checks\n",
    "            import re\n",
    "            version_match = re.search(r'(\\d+\\.\\d+\\.\\d+)', version_info)\n",
    "            if version_match:\n",
    "                version = version_match.group(1)\n",
    "                print(f\"   ‚ÑπÔ∏è  Version {version} detected - using compatible deployment options\")\n",
    "                \n",
    "                # Check if this is an older version\n",
    "                major, minor, patch = map(int, version.split('.'))\n",
    "                if major == 0 and minor < 26:\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: Version {version} is older than 0.26.6\")\n",
    "                    print(f\"   üí° Consider upgrading: pip install --upgrade --force-reinstall leptonai\")\n",
    "                \n",
    "                return version\n",
    "        return \"unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not determine version: {e}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "def check_authentication_status(lepton_cmd):\n",
    "    \"\"\"Check if Lepton CLI is properly authenticated\"\"\"\n",
    "    try:\n",
    "        print(\"   üîê Checking authentication status...\")\n",
    "        \n",
    "        # Try to get workspace info - this will fail if not authenticated\n",
    "        result = subprocess.run([lepton_cmd, 'workspace', 'list'], capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(\"   ‚úÖ Authentication confirmed - workspace access working\")\n",
    "            return True\n",
    "        else:\n",
    "            error_msg = result.stderr.strip() or result.stdout.strip()\n",
    "            if 'auth' in error_msg.lower() or 'token' in error_msg.lower() or 'login' in error_msg.lower():\n",
    "                print(\"   ‚ùå Authentication required - need to run 'lep login'\")\n",
    "                return False\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  Could not verify authentication status\")\n",
    "                return False\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not check authentication: {e}\")\n",
    "        return False\n",
    "\n",
    "def image_to_base64(image_bytes):\n",
    "    \"\"\"Convert image bytes to base64 string for API transmission\"\"\"\n",
    "    try:\n",
    "        # Convert bytes to base64 string\n",
    "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        return base64_string\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting image to base64: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_available_resources(lepton_cmd):\n",
    "    \"\"\"Check available resources in Lepton workspace\"\"\"\n",
    "    try:\n",
    "        print(\"   üîç Checking available resources...\")\n",
    "        \n",
    "        # Try to list existing deployments to see if any resources are in use\n",
    "        result = subprocess.run([lepton_cmd, 'deployment', 'list'], capture_output=True, text=True, timeout=15)\n",
    "        if result.returncode == 0:\n",
    "            deployments = result.stdout.strip()\n",
    "            if deployments and 'No deployments found' not in deployments:\n",
    "                print(\"   ‚ö†Ô∏è  Found existing deployments - resources may be limited\")\n",
    "                print(\"   üí° Consider using smaller resource shapes or waiting for resources to free up\")\n",
    "            else:\n",
    "                print(\"   ‚úÖ No existing deployments found - resources should be available\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Could not check existing deployments\")\n",
    "            \n",
    "        # Try to get workspace info\n",
    "        try:\n",
    "            ws_result = subprocess.run([lepton_cmd, 'workspace', 'list'], capture_output=True, text=True, timeout=10)\n",
    "            if ws_result.returncode == 0:\n",
    "                print(\"   ‚úÖ Workspace access confirmed\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  Could not verify workspace access\")\n",
    "        except Exception:\n",
    "            print(\"   ‚ö†Ô∏è  Could not check workspace status\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not check resources: {e}\")\n",
    "\n",
    "def try_deployment_create(model, endpoint_name, resource_type, node_group, hf_token, image_pull_secrets):\n",
    "    \"\"\"\n",
    "    Attempt deployment creation using formal lep deployment create command.\n",
    "    This follows the formal deployment create syntax with user-provided values.\n",
    "    \"\"\"\n",
    "\n",
    "    lepton_cmd = os.environ.get('LEPTON_CMD', 'lep')\n",
    "    if not lepton_cmd:\n",
    "        return False, \"No CLI command available for deployment create - please complete manual login first\"\n",
    "    \n",
    "    # Check version first\n",
    "    version = check_lepton_version(lepton_cmd)\n",
    "    \n",
    "    # Check authentication status\n",
    "    if not check_authentication_status(lepton_cmd):\n",
    "        return False, \"‚ùå Authentication required. Please complete manual login first:\\n\" \\\n",
    "                     \"1. Run: lep login\\n\" \\\n",
    "                     \"2. Follow the interactive prompts\\n\" \\\n",
    "                     \"3. Copy URL to browser and create token\\n\" \\\n",
    "                     \"4. Paste workspace:token back in terminal\\n\" \\\n",
    "                     \"5. Try deployment again\"\n",
    "    \n",
    "    # Check available resources\n",
    "    check_available_resources(lepton_cmd)\n",
    "\n",
    "    nim_containers = {\n",
    "        'flux.1-dev': 'nvcr.io/nim/black-forest-labs/flux.1-dev:1.1.0',\n",
    "        'flux.1-kontext-dev': 'nvcr.io/nim/black-forest-labs/flux.1-kontext-dev:1.0.0'\n",
    "    }\n",
    "\n",
    "    container_image = nim_containers[model]\n",
    "    ngc_key = os.environ.get('NGC_API_KEY')\n",
    "\n",
    "    print(f\"üöÄ Attempting lep deployment create...\")\n",
    "    print(f\"   üì¶ Container: {container_image}\")\n",
    "    print(f\"   üè∑Ô∏è  Name: {endpoint_name}\")\n",
    "    print(f\"   üí° Note: Periods in names automatically converted to hyphens for Lepton compatibility\")\n",
    "    print(f\"   üîß Resources: {resource_type}\")\n",
    "    print(f\"   üè¢ Node Group: {node_group}\")\n",
    "    print(f\"   üîë Image Pull Secrets: {image_pull_secrets}\")\n",
    "    print(f\"   üîç DEBUG - HF Token received: '{'*' * min(len(hf_token), 10) if hf_token else 'EMPTY'}{'...' if len(hf_token) > 10 else ''}' (length: {len(hf_token)})\")\n",
    "\n",
    "    try:\n",
    "        # Set environment variables for the subprocess\n",
    "        env = os.environ.copy()\n",
    "        if ngc_key:\n",
    "            env['NGC_API_KEY'] = ngc_key\n",
    "        if hf_token:\n",
    "            env['HF_TOKEN'] = hf_token\n",
    "\n",
    "        # Build deployment create command using formal syntax\n",
    "        print(f\"   üîç Using formal deployment create syntax: {lepton_cmd} deployment create\")\n",
    "        \n",
    "        # Build command based on formal deployment create syntax\n",
    "        # Reference: Formal deployment create syntax with user-provided values\n",
    "        cmd_parts = [\n",
    "            lepton_cmd,\n",
    "            'deployment', 'create',\n",
    "            '--name', endpoint_name,  # Deployment name\n",
    "            '--container-image', container_image,  # NIM container image\n",
    "            '--container-port', '8000',  # NIM containers use port 8000\n",
    "            '--resource-shape', resource_type,  # GPU resource shape\n",
    "            '--replicas-static', '1',  # Static replica count\n",
    "            '--env', f'NGC_API_KEY={ngc_key}',  # NGC API key environment variable\n",
    "            '--public',  # Make deployment publicly accessible\n",
    "            '--node-group', node_group,  # User-provided node group\n",
    "            '--image-pull-secrets', image_pull_secrets  # User-provided image pull secrets\n",
    "        ]\n",
    "        \n",
    "        # HF_TOKEN is always required for FLUX NIMs (confirmed through testing)\n",
    "        if not hf_token or not hf_token.strip():\n",
    "            return False, \"‚ùå HF_TOKEN is required for FLUX NIM deployments. Please provide a valid Hugging Face token.\"\n",
    "        \n",
    "        cmd_parts.extend(['--env', f'HF_TOKEN={hf_token}'])\n",
    "        print(f\"   üîë Including required HF_TOKEN for FLUX NIM authentication\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Using formal deployment create syntax: --name, --container-image, --container-port, --resource-shape, --replicas-static, --env, --public, --node-group, --image-pull-secrets\")\n",
    "\n",
    "        print(f\"   üîÑ Running command: {' '.join(cmd_parts[:6])} [...]\")\n",
    "        print(\"   üí° Note: [...] indicates the command continues with more parameters\")\n",
    "\n",
    "        result = subprocess.run(cmd_parts, capture_output=True, text=True, env=env, timeout=120)\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   ‚úÖ Deployment creation successful!\")\n",
    "            print(f\"   üìã Output: {result.stdout.strip()}\")\n",
    "\n",
    "            # Extract deployment URL from output if available\n",
    "            deployment_url = None\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if ('deployment' in line.lower() or 'endpoint' in line.lower()) and ('http' in line or 'https' in line):\n",
    "                    # Try to extract URL from the output\n",
    "                    import re\n",
    "                    url_match = re.search(r'https?://[^\\s]+', line)\n",
    "                    if url_match:\n",
    "                        deployment_url = url_match.group(0)\n",
    "                        break\n",
    "\n",
    "            if not deployment_url:\n",
    "                # Generate expected URL pattern based on Lepton conventions\n",
    "                deployment_url = f\"https://{endpoint_name}.cloud.lepton.ai\"\n",
    "\n",
    "            return True, f\"Deployment created successfully. URL: {deployment_url}\"\n",
    "\n",
    "        else:\n",
    "            error_msg = result.stderr.strip() or result.stdout.strip()\n",
    "            print(f\"   ‚ùå Deployment creation failed: {error_msg}\")\n",
    "\n",
    "            # Check for specific error patterns and provide actionable feedback\n",
    "            if 'command not found' in error_msg.lower() or 'not recognized' in error_msg.lower():\n",
    "                return False, \"lep deployment command not available - CLI version may not support this feature\"\n",
    "            elif 'no available node groups' in error_msg.lower():\n",
    "                return False, f\"‚ùå No GPU resources available for new deployments. This means:\\n\" \\\n",
    "                             f\"   ‚Ä¢ Your H200 DevPod is already using the GPU resources\\n\" \\\n",
    "                             f\"   ‚Ä¢ You need additional GPU quota for separate deployments\\n\" \\\n",
    "                             f\"   ‚Ä¢ Try using the Lepton web interface instead\\n\" \\\n",
    "                             f\"   ‚Ä¢ Check Lepton dashboard for available resources\\n\" \\\n",
    "                             f\"   ‚Ä¢ Consider upgrading your Lepton plan for more GPU quota\"\n",
    "            elif 'container-image' in error_msg.lower():\n",
    "                return False, f\"Container image issue: {error_msg}\"\n",
    "            elif 'resource-shape' in error_msg.lower():\n",
    "                return False, f\"Resource configuration issue: {error_msg}\"\n",
    "            elif 'authentication' in error_msg.lower() or 'token' in error_msg.lower() or 'auth_token' in error_msg.lower():\n",
    "                return False, f\"‚ùå Authentication issue: {error_msg}\\n\" \\\n",
    "                             f\"   üí° This means you need to complete the manual login process:\\n\" \\\n",
    "                             f\"   1. Run: lep login\\n\" \\\n",
    "                             f\"   2. Follow the interactive prompts\\n\" \\\n",
    "                             f\"   3. Copy the URL to browser and create token\\n\" \\\n",
    "                             f\"   4. Paste the workspace:token back in terminal\\n\" \\\n",
    "                             f\"   5. Try deployment again\"\n",
    "            elif 'timeout' in error_msg.lower() or 'deprecated' in error_msg.lower():\n",
    "                return False, f\"‚ùå Deprecated option detected. The notebook has been updated to use --replicas-static instead of --no-traffic-timeout. Please try again.\"\n",
    "            else:\n",
    "                return False, f\"Deployment creation failed: {error_msg}\"\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Deployment creation command timed out after 2 minutes - deployment may still be in progress\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Deployment creation error: {str(e)}\"\n",
    "\n",
    "def try_deployment_api(model, endpoint_name, resource_type):\n",
    "    \"\"\"\n",
    "    Attempt deployment creation using Python API as fallback.\n",
    "    Uses the leptonai.api.deployment module if available.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(\"üêç Attempting Python API deployment creation...\")\n",
    "\n",
    "        import leptonai\n",
    "        print(f\"   ‚úÖ Leptonai version: {leptonai.__version__ if hasattr(leptonai, '__version__') else 'unknown'}\")\n",
    "\n",
    "        nim_containers = {\n",
    "            'flux.1-dev': 'nvcr.io/nim/black-forest-labs/flux.1-dev:1.1.0',\n",
    "            'flux.1-kontext-dev': 'nvcr.io/nim/black-forest-labs/flux.1-kontext-dev:1.0.0'\n",
    "        }\n",
    "\n",
    "        container_image = nim_containers[model]\n",
    "        ngc_key = os.environ.get('NGC_API_KEY')\n",
    "\n",
    "        print(f\"   üì¶ Container: {container_image}\")\n",
    "        print(f\"   üè∑Ô∏è  Name: {endpoint_name}\")\n",
    "        print(f\"   üîß Resources: {resource_type}\")\n",
    "\n",
    "        # Try to use the deployment API from leptonai.api\n",
    "        try:\n",
    "            from leptonai.api import deployment\n",
    "            print(\"   ‚úÖ Deployment API available\")\n",
    "\n",
    "            # Attempt to create deployment using API based on GitHub source\n",
    "            deployment_config = {\n",
    "                'name': endpoint_name,\n",
    "                'container_image': container_image,  # Use 'container_image' parameter as per GitHub source\n",
    "                'container_port': 8000,\n",
    "                'resource_shape': resource_type,  # Use 'resource_shape' for GPU configuration\n",
    "                'env': {'NGC_API_KEY': ngc_key} if ngc_key else {},\n",
    "                'public': True\n",
    "            }\n",
    "\n",
    "            print(f\"   üîÑ Creating deployment via API...\")\n",
    "\n",
    "            # Try different API call patterns\n",
    "            try:\n",
    "                # Method 1: Direct create call\n",
    "                deployment_result = deployment.create(**deployment_config)\n",
    "                if deployment_result:\n",
    "                    print(f\"   ‚úÖ Python API deployment creation successful!\")\n",
    "                    return True, f\"Deployment created via API: {deployment_result}\"\n",
    "            except Exception as api_err:\n",
    "                print(f\"   ‚ùå Direct API deployment creation failed: {str(api_err)}\")\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"   ‚ùå Deployment API not available in this leptonai version\")\n",
    "\n",
    "        # Fallback: Explore available API methods\n",
    "        try:\n",
    "            api_modules = []\n",
    "            for attr in dir(leptonai):\n",
    "                if 'api' in attr.lower():\n",
    "                    api_modules.append(attr)\n",
    "\n",
    "            if api_modules:\n",
    "                print(f\"   üí° Available API modules: {api_modules}\")\n",
    "\n",
    "            # Check for deployment-related methods\n",
    "            deployment_methods = [attr for attr in dir(leptonai) if 'create' in attr.lower() or 'deployment' in attr.lower()]\n",
    "            if deployment_methods:\n",
    "                print(f\"   üí° Found potential deployment methods: {deployment_methods}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return False, \"Python API deployment creation methods not available in this leptonai version\"\n",
    "\n",
    "    except ImportError:\n",
    "        return False, \"leptonai package not available for Python API deployment creation\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Python API deployment creation error: {str(e)}\"\n",
    "\n",
    "def generate_corrected_deployment_guide(model, endpoint_name, resource_type, node_group, hf_token, image_pull_secrets):\n",
    "    \"\"\"Generate manual deployment guide with corrected approach\"\"\"\n",
    "\n",
    "    nim_containers = {\n",
    "        'flux.1-dev': 'nvcr.io/nim/black-forest-labs/flux.1-dev:1.1.0',\n",
    "        'flux.1-kontext-dev': 'nvcr.io/nim/black-forest-labs/flux.1-kontext-dev:1.0.0'\n",
    "    }\n",
    "\n",
    "    container_image = nim_containers[model]\n",
    "    ngc_key = os.environ.get('NGC_API_KEY', 'your-ngc-api-key')\n",
    "\n",
    "    print(\"üìã Corrected Manual Deployment Guide\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üéØ Model: {model}\")\n",
    "    print(f\"üè∑Ô∏è  Name: {endpoint_name}\")\n",
    "    print(f\"üì¶ Container: {container_image}\")\n",
    "    print(f\"üîß Resources: {resource_type}\")\n",
    "    print()\n",
    "\n",
    "    print(\"üåê OPTION 1: Lepton Web Interface (Recommended)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"1. Go to: https://dashboard.lepton.ai/\")\n",
    "    print(\"2. Click 'Create' or '+ New' button\")\n",
    "    print(\"3. Select 'Deployment' or 'Endpoint'\")\n",
    "    print(\"4. Fill in the form:\")\n",
    "    print(f\"   ‚Ä¢ Name: {endpoint_name}\")\n",
    "    print(f\"   ‚Ä¢ Container Image: {container_image}\")\n",
    "    print(f\"   ‚Ä¢ Resource Type: {resource_type}\")\n",
    "    print(\"   ‚Ä¢ Environment Variables:\")\n",
    "    print(f\"     - Key: NGC_API_KEY\")\n",
    "    print(f\"     - Value: {ngc_key}\")\n",
    "    print(\"   ‚Ä¢ Port: 8000\")\n",
    "    print(\"   ‚Ä¢ Public Access: ‚úÖ Enabled\")\n",
    "    print(\"5. Click 'Create' or 'Deploy'\")\n",
    "    print(\"6. Wait 3-5 minutes for deployment\")\n",
    "    print(\"7. Copy the endpoint URL when ready\")\n",
    "    print()\n",
    "\n",
    "    print(\"üîß OPTION 2: Correct CLI Syntax (GitHub Source)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Use the proper deployment create command from GitHub source code:\")\n",
    "    print(\"Reference: https://github.com/leptonai/leptonai/blob/main/leptonai/cli/deployment.py#L821\")\n",
    "    print()\n",
    "    print(\"# Check deployment commands are available:\")\n",
    "    print(\"lep deployment --help\")\n",
    "    print(\"lep deployment create -h\")\n",
    "    print()\n",
    "    print(\"# Create deployment with formal syntax:\")\n",
    "    print(f\"lep deployment create \\\\\")\n",
    "    print(f\"  --name {endpoint_name} \\\\\")\n",
    "    print(f\"  --container-image {container_image} \\\\\")\n",
    "    print(f\"  --container-port 8000 \\\\\")\n",
    "    print(f\"  --resource-shape {resource_type} \\\\\")\n",
    "    print(f\"  --replicas-static 1 \\\\\")\n",
    "    print(f\"  --env NGC_API_KEY={ngc_key} \\\\\")\n",
    "    print(f\"  --public \\\\\")\n",
    "    print(f\"  --node-group {node_group} \\\\\")\n",
    "    print(f\"  --image-pull-secrets {image_pull_secrets} \\\\\")\n",
    "    print(f\"  --env HF_TOKEN={hf_token}\")\n",
    "    \n",
    "    # Validation reminder\n",
    "    if not hf_token or not hf_token.strip():\n",
    "        print(\"  # ‚ö†Ô∏è  WARNING: HF_TOKEN is required for FLUX NIMs!\")\n",
    "    print()\n",
    "    print(\"# Check deployment status:\")\n",
    "    print(\"lep deployment list\")\n",
    "    print(f\"lep deployment status {endpoint_name}\")\n",
    "    print()\n",
    "\n",
    "    print(\"‚ùå AVOID: Photon-based deployment (incorrect approach)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"The following commands are NOT correct for NIM containers:\")\n",
    "    print(\"‚ùå lep photon run --container-image ...\")\n",
    "    print(\"‚ùå lep photon create ...\")\n",
    "    print(\"‚ùå lep deployment create ... (deprecated)\")\n",
    "    print(\"‚ùå Python API photon methods\")\n",
    "    print()\n",
    "    print(\"NIMs should be deployed as container-based endpoints,\")\n",
    "    print(\"not as photons. Use lep endpoint create instead.\")\n",
    "    print()\n",
    "\n",
    "    print(\"üîç Expected Endpoint URL Pattern:\")\n",
    "    print(f\"https://{endpoint_name}.cloud.lepton.ai\")\n",
    "    print(\"or\")\n",
    "    print(f\"https://{endpoint_name}--{resource_type.replace('.', '-')}.cloud.lepton.ai\")\n",
    "    print()\n",
    "\n",
    "    return endpoint_name, container_image\n",
    "\n",
    "def start_corrected_nim_deployment():\n",
    "    \"\"\"Start NIM deployment process with corrected approach\"\"\"\n",
    "    model = nim_model_selector.value\n",
    "    endpoint_name = endpoint_name_widget.value.strip()\n",
    "    resource_type = resource_type_widget.value\n",
    "    node_group = node_group_input.value.strip()\n",
    "    hf_token = hf_token_input.value.strip()\n",
    "    image_pull_secrets = image_pull_secrets_input.value.strip()\n",
    "\n",
    "    with deployment_output:\n",
    "        deployment_output.clear_output(wait=True)\n",
    "        \n",
    "        print(\"üîç Corrected NIM Deployment Strategy\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Using proper lep deployment create instead of photon methods\")\n",
    "        \n",
    "        # Debug: Show what values were retrieved from widgets\n",
    "        print(\"üîç DEBUG: Widget Values Retrieved:\")\n",
    "        print(f\"   üìù Endpoint Name: '{endpoint_name}'\")\n",
    "        print(f\"   üîß Resource Type: '{resource_type}'\")\n",
    "        print(f\"   üè¢ Node Group: '{node_group}'\")\n",
    "        print(f\"   üîë HF Token: '{'*' * min(len(hf_token), 10) if hf_token else 'EMPTY'}{'...' if len(hf_token) > 10 else ''}' (length: {len(hf_token)})\")\n",
    "        print(f\"   üîê Image Pull Secrets: '{image_pull_secrets}'\")\n",
    "        print()\n",
    "        \n",
    "        # Validate required inputs\n",
    "        if not hf_token or not hf_token.strip():\n",
    "            print(\"‚ùå DEPLOYMENT FAILED: HF_TOKEN is required!\")\n",
    "            print(\"üìã Please provide a valid Hugging Face token:\")\n",
    "            print(\"   1. Go to https://huggingface.co/settings/tokens\")\n",
    "            print(\"   2. Create a token with 'Read' permissions\")\n",
    "            print(\"   3. Enter the token in the HF Token field above\")\n",
    "            print(\"   4. Try deployment again\")\n",
    "            print()\n",
    "            print(\"üîç TROUBLESHOOTING:\")\n",
    "            print(f\"   ‚Ä¢ Widget exists: {'hf_token_input' in globals()}\")\n",
    "            if 'hf_token_input' in globals():\n",
    "                print(f\"   ‚Ä¢ Widget value: '{hf_token_input.value}' (raw)\")\n",
    "                print(f\"   ‚Ä¢ Widget value stripped: '{hf_token_input.value.strip()}' (processed)\")\n",
    "            return\n",
    "        print()\n",
    "\n",
    "        # Generate endpoint name if not provided\n",
    "        if not endpoint_name:\n",
    "            # Simple, clean name for FLUX.1-dev\n",
    "            endpoint_name = \"flux-dev\"\n",
    "        else:\n",
    "            # Sanitize user-provided endpoint name to ensure it meets Lepton requirements\n",
    "            # Replace periods and other invalid characters with hyphens\n",
    "            endpoint_name = endpoint_name.replace('.', '-').replace('_', '-').lower()\n",
    "\n",
    "        # Check if CLI is available and user has completed manual login\n",
    "        lepton_cmd = os.environ.get('LEPTON_CMD', '')\n",
    "        if not lepton_cmd:\n",
    "            print(\"‚ùå No working CLI command available\")\n",
    "            print(\"üìã Please complete the Lepton CLI setup in the previous cell first\")\n",
    "            print(\"üìã Then proceed with manual deployment guide...\")\n",
    "            generate_corrected_deployment_guide(model, endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "            return\n",
    "\n",
    "        print(\"üîç Discovering deployment CLI capabilities...\")\n",
    "        syntax_info = discover_deployment_cli_syntax()\n",
    "\n",
    "        has_deployment_create = False\n",
    "        print(\"üìã CLI Command Analysis:\")\n",
    "        for desc, output in syntax_info.items():\n",
    "            if \"Error:\" not in output and \"Exception:\" not in output:\n",
    "                print(f\"‚úÖ {desc}: Available\")\n",
    "                if \"deployment create\" in desc.lower():\n",
    "                    has_deployment_create = True\n",
    "                    # Show key parameters\n",
    "                    lines = output.split('\\n')\n",
    "                    relevant_lines = [line.strip() for line in lines if '--' in line and\n",
    "                                    any(param in line.lower() for param in ['model', 'port', 'env', 'public', 'gpu'])]\n",
    "                    for line in relevant_lines[:5]:  # Show first 5 relevant options\n",
    "                        print(f\"   üí° {line}\")\n",
    "            else:\n",
    "                print(f\"‚ùå {desc}: Not available\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Determine models to deploy\n",
    "        # Deploy FLUX.1-dev model\n",
    "        deploy_model = model  # Should always be 'flux.1-dev' now\n",
    "        current_endpoint_name = endpoint_name\n",
    "\n",
    "        print(f\"\\nüé® Deploying: {deploy_model}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        if has_deployment_create:\n",
    "            # Try the correct deployment create approach\n",
    "            print(\"üöÄ Attempting lep deployment create...\")\n",
    "            create_success, create_result = try_deployment_create(deploy_model, current_endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "\n",
    "            if create_success:\n",
    "                print(\"‚úÖ Deployment create successful!\")\n",
    "                print(f\"üìã Result: {create_result}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Deployment create failed: {create_result}\")\n",
    "                \n",
    "                # Try Python API as fallback\n",
    "                print(\"üêç Attempting Python API deployment creation...\")\n",
    "                api_success, api_result = try_deployment_api(deploy_model, current_endpoint_name, resource_type)\n",
    "\n",
    "                if api_success:\n",
    "                    print(\"‚úÖ Python API deployment creation successful!\")\n",
    "                    print(f\"üìã Result: {api_result}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Python API deployment creation failed: {api_result}\")\n",
    "                    print(\"\\nüìã Manual deployment creation required for this model:\")\n",
    "                    generate_corrected_deployment_guide(deploy_model, current_endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "        else:\n",
    "            print(\"‚ùå No working CLI command available\")\n",
    "            print(\"üìã Please complete the Lepton CLI setup in the previous cell first\")\n",
    "            print(\"üìã Then proceed with manual deployment guide...\")\n",
    "            generate_corrected_deployment_guide(deploy_model, current_endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä Next Steps Summary\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1. üîê Complete manual Lepton login in terminal (if not done)\")\n",
    "        print(\"2. ‚úÖ Complete any manual deployment creation via https://dashboard.lepton.ai/\")\n",
    "        print(\"3. ‚è±Ô∏è  Wait 3-5 minutes for deployments to become ready\")\n",
    "        print(\"4. üìã Copy deployment URLs from Lepton dashboard\")\n",
    "        print(\"5. üîÑ Return to this notebook\")\n",
    "        print(\"6. üìù Use 'Custom NIM Endpoint' in the configuration\")\n",
    "        print(\"7. üé® Continue with image generation experiments\")\n",
    "        print()\n",
    "        print(\"üí° The corrected approach uses lep deployment create\")\n",
    "        print(\"   following GitHub source code implementation.\")\n",
    "        print(\"‚ö†Ô∏è  Remember: Manual login required before deployment creation!\")\n",
    "        print()\n",
    "        print(\"   If Lepton deployment fails due to resource limits:\")\n",
    "        print()\n",
    "        print(\"üîß TROUBLESHOOTING TIPS:\")\n",
    "        print(\"   ‚Ä¢ If you get 'auth_token' errors: Complete manual login with 'lep login'\")\n",
    "        print(\"   ‚Ä¢ If you get 'no available node groups': Your DevPod is using the GPU resources\")\n",
    "        print(\"   ‚Ä¢ Or use the Lepton web interface for deployment\")\n",
    "        print(\"   ‚Ä¢ Check your Lepton workspace quota and billing\")\n",
    "        print(\"   ‚Ä¢ Use --replicas-static 1 to keep deployment running (new option)\")\n",
    "        print(\"   ‚Ä¢ Consider upgrading your Lepton plan for more GPU quota\")\n",
    "\n",
    "# Create deployment interface\n",
    "print(\"üöÄ FLUX NIM Endpoint Deployment (CORRECTED)\")\n",
    "print(\"Deploy production-ready FLUX NIMs using proper deployment methods\")\n",
    "print(\"‚è±Ô∏è  Expected time: 3-5 minutes per model\")\n",
    "print(\"üìä Resource requirements: 1 GPU per endpoint\")\n",
    "print()\n",
    "print(\"üéØ DEPLOYING FLUX.1 DEV:\")\n",
    "print(\"  ‚Ä¢ Text-to-Image Generation: Create images from text prompts\")\n",
    "print(\"  ‚Ä¢ Balanced Performance: Optimized for quality and speed\")\n",
    "print(\"  ‚Ä¢ Production Ready: Suitable for most use cases\")\n",
    "print()\n",
    "print(\"üîß KEY CORRECTION: Using lep deployment create (Formal syntax approach)\")\n",
    "print(\"‚ö†Ô∏è  PREREQUISITE: Complete manual Lepton login in previous cell first!\")\n",
    "print()\n",
    "print(\"üìã SETUP REQUIREMENTS:\")\n",
    "print(\"1. üîë Hugging Face Token: REQUIRED for all FLUX NIMs - Get from https://huggingface.co/settings/tokens\")\n",
    "print(\"2. üè¢ Node Group: Your specific node group name (e.g., tme-nebius-h200-01)\")\n",
    "print(\"3. üîê Image Pull Secrets: Create in Lepton Settings ‚Üí Registries ‚Üí Private Image Registry Auth\")\n",
    "print(\"   ‚Ä¢ Go to Lepton Dashboard ‚Üí Settings ‚Üí Registries\")\n",
    "print(\"   ‚Ä¢ Click 'Create Private Image Registry Auth'\")\n",
    "print(\"   ‚Ä¢ Name it (e.g., 'roclark-ngc')\")\n",
    "print(\"   ‚Ä¢ This will be used for --image-pull-secrets parameter\")\n",
    "print()\n",
    "\n",
    "display(nim_model_selector)\n",
    "display(endpoint_name_widget)\n",
    "display(resource_type_widget)\n",
    "\n",
    "# Additional required inputs\n",
    "print(\"üîß Additional Required Configuration:\")\n",
    "print(\"Please provide the following information for deployment:\")\n",
    "\n",
    "# Node group input\n",
    "node_group_input = widgets.Text(\n",
    "    value='tme-nebius-h200-01',  # Default from user's DevPod\n",
    "    placeholder='Enter your node group name (e.g., tme-nebius-h200-01)',\n",
    "    description='Node Group:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px', height='50px')\n",
    ")\n",
    "\n",
    "# Hugging Face token input\n",
    "hf_token_input = widgets.Password(\n",
    "    value='',\n",
    "    placeholder='Enter your Hugging Face token (hf_...)',\n",
    "    description='HF Token:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px', height='50px')\n",
    ")\n",
    "\n",
    "# Image pull secrets input\n",
    "image_pull_secrets_input = widgets.Text(\n",
    "    value='roclark-ngc',  # Default from example\n",
    "    placeholder='Enter your image pull secrets name',\n",
    "    description='Image Pull Secrets:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px', height='50px')\n",
    ")\n",
    "\n",
    "display(node_group_input)\n",
    "display(hf_token_input)\n",
    "display(image_pull_secrets_input)\n",
    "\n",
    "# Debug button to test widget values\n",
    "def test_widget_values():\n",
    "    print(\"üîç WIDGET VALUE TEST:\")\n",
    "    print(f\"   üè¢ Node Group: '{node_group_input.value}'\")\n",
    "    print(f\"   üîë HF Token: '{'*' * min(len(hf_token_input.value), 10) if hf_token_input.value else 'EMPTY'}{'...' if len(hf_token_input.value) > 10 else ''}' (length: {len(hf_token_input.value)})\")\n",
    "    print(f\"   üîê Image Pull Secrets: '{image_pull_secrets_input.value}'\")\n",
    "\n",
    "\n",
    "deploy_nim_button = widgets.Button(\n",
    "    description='üöÄ Deploy',\n",
    "    button_style='success',\n",
    "    icon='rocket',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "deploy_nim_button.on_click(lambda b: start_corrected_nim_deployment())\n",
    "display(deploy_nim_button)\n",
    "display(deployment_output)\n",
    "\n",
    "print(\"\\nüí° Deployment Strategy:\")\n",
    "print(\"  ‚Ä¢ Uses lep deployment create for container-based deployment\")\n",
    "print(\"  ‚Ä¢ Provides comprehensive error handling and user guidance\")\n",
    "print(\"  ‚Ä¢ Web interface deployment creation is also available as alternative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Images\n",
    "\n",
    "### Background: Understanding NIM API Communication\n",
    "\n",
    "**NIM API Architecture:**\n",
    "NVIDIA NIMs expose a standardized REST API that follows OpenAI-compatible patterns:\n",
    "\n",
    "- **Endpoint Pattern**: `/v1/infer` - Standardized inference endpoint\n",
    "- **HTTP Method**: POST - Sends generation parameters\n",
    "- **Content Type**: `application/json` - Structured data format\n",
    "- **Response Format**: JSON with base64-encoded images in `artifacts` array\n",
    "\n",
    "**API Payload Structure:**\n",
    "```json\n",
    "{\n",
    "  \"prompt\": \"Your text description\",\n",
    "  \"mode\": \"base\",           // \"base\" for generation, \"kontext\" for editing\n",
    "  \"seed\": 12345,           // Random seed for reproducibility\n",
    "  \"steps\": 50              // Number of inference iterations\n",
    "```\n",
    "\n",
    "**Response Structure:**\n",
    "```json\n",
    "{\n",
    "  \"artifacts\": [\n",
    "    {\n",
    "      \"base64\": \"iVBORw0KGgoAAAANSUhEUgAA...\",  // Base64 image data\n",
    "      \"seed\": 12345,                            // Actual seed used\n",
    "      \"finish_reason\": \"SUCCESS\"\n",
    "    }\n",
    "  ]\n",
    "```\n",
    "\n",
    "**Image Processing Pipeline:**\n",
    "1. **API Request**: Send prompt + parameters to NIM endpoint\n",
    "2. **Model Inference**: NIM processes request on GPU\n",
    "3. **Base64 Encoding**: NIM encodes result image as base64 string\n",
    "4. **Response Parsing**: Extract base64 data from artifacts array\n",
    "5. **Image Decoding**: Convert base64 back to PIL Image object\n",
    "6. **Display**: Render image using matplotlib\n",
    "7. **Storage**: Save image to local filesystem\n",
    "\n",
    "**Performance Measurement:**\n",
    "- **Timing**: Measure end-to-end request duration\n",
    "**Error Handling:**\n",
    "- **Network Issues**: Timeout, connection errors\n",
    "- **API Errors**: Invalid parameters, server errors  \n",
    "- **Image Processing**: Decoding failures, display issues\n",
    "- **Graceful Degradation**: Continue with other models if one fails\n",
    "\n",
    "**What the Generation Code Does:**\n",
    "- **API Communication**: Handles HTTP requests to NIM endpoints\n",
    "- **Image Processing**: Converts between base64, binary, and display formats  \n",
    "- **Performance Tracking**: Times each generation for comparison\n",
    "- **Error Management**: Provides detailed error messages for troubleshooting\n",
    "- **File Management**: Automatically saves images with metadata\n",
    "- **UI Integration**: Displays results inline with interactive elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image generation and comparison function\n",
    "def generate_with_nim(endpoint, ngc_api_key, model, prompt, steps, seed):\n",
    "    \"\"\"Generate image using actual NIM endpoint with correct API format\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Note: This deployment is public, no authentication required\n",
    "    # Authentication headers removed for public Lepton deployments\n",
    "    \n",
    "    # Official NIM API payload format (from NVIDIA documentation)\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"mode\": \"base\",  # NIM uses mode parameter\n",
    "        \"seed\": seed,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use the official NIM API endpoint pattern\n",
    "        nim_endpoint = endpoint.rstrip('/') + '/v1/infer'\n",
    "        # Debug output to show what's being sent\n",
    "        print(f\"   üîç Endpoint: {nim_endpoint}\")\n",
    "        print(f\"   üìã Payload: {payload}\")\n",
    "        print(f\"   üåê Public deployment - no authentication required\")\n",
    "        \n",
    "        response = requests.post(nim_endpoint, headers=headers, json=payload, timeout=120)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generation_time = end_time - start_time\n",
    "            \n",
    "            # Correct NIM response parsing - images are in artifacts array\n",
    "            if 'artifacts' in result and len(result['artifacts']) > 0:\n",
    "                base64_image = result['artifacts'][0].get('base64')\n",
    "                if base64_image:\n",
    "                    return {\n",
    "                        'success': True,\n",
    "                        'image_base64': base64_image,\n",
    "                        'generation_time': generation_time,\n",
    "                        'model': model,\n",
    "                        'endpoint': endpoint,\n",
    "                        'seed': result['artifacts'][0].get('seed', seed)\n",
    "                    }\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f\"No image artifacts in response: {result}\",\n",
    "                'model': model,\n",
    "                'endpoint': endpoint\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f\"NIM API Error: {response.status_code} - {response.text}\",\n",
    "                'model': model,\n",
    "                'endpoint': endpoint\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f\"Request failed: {str(e)}\",\n",
    "            'model': model,\n",
    "            'endpoint': endpoint\n",
    "        }\n",
    "\n",
    "def display_image_from_base64(base64_data, title=\"Generated Image\"):\n",
    "    \"\"\"Convert base64 to PIL Image and display in Jupyter\"\"\"\n",
    "    try:\n",
    "        # Decode base64 to bytes\n",
    "        image_bytes = base64.b64decode(base64_data)\n",
    "        \n",
    "        # Create PIL Image from bytes\n",
    "        image = PILImage.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        print(f\"üñºÔ∏è  Displaying image: {title}\")\n",
    "        print(f\"   üìè Size: {image.size[0]}x{image.size[1]} pixels\")\n",
    "        \n",
    "        # Try multiple display methods for better Jupyter compatibility\n",
    "        try:\n",
    "            # Method 1: Use matplotlib with proper inline display (most reliable)\n",
    "            import matplotlib\n",
    "            matplotlib.use('inline')  # Ensure inline backend\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "            plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Force display in current output area\n",
    "            from IPython.display import display as ipython_display\n",
    "            ipython_display(plt.gcf())\n",
    "            plt.close()  # Close to prevent duplicate display\n",
    "            \n",
    "            print(\"   ‚úÖ Image displayed using matplotlib\")\n",
    "        except Exception as e1:\n",
    "            print(f\"   ‚ö†Ô∏è  Matplotlib failed: {e1}\")\n",
    "            try:\n",
    "                # Method 2: Use IPython.display as fallback\n",
    "                from IPython.display import Image as IPImage, display as ipython_display\n",
    "                ipython_display(IPImage(data=image_bytes))\n",
    "                print(\"   ‚úÖ Image displayed using IPython.display\")\n",
    "            except Exception as e2:\n",
    "                print(f\"   ‚ùå Both display methods failed: {e2}\")\n",
    "                print(\"   üí° Image object created successfully (display methods failed)\")\n",
    "        \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_image_from_base64(base64_data, filepath):\n",
    "    \"\"\"Save base64 image data to file\"\"\"\n",
    "    try:\n",
    "        # Decode base64 to bytes\n",
    "        image_bytes = base64.b64decode(base64_data)\n",
    "        \n",
    "        # Create PIL Image and save\n",
    "        image = PILImage.open(io.BytesIO(image_bytes))\n",
    "        image.save(filepath)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving image to {filepath}: {e}\")\n",
    "        return False\n",
    "\n",
    "def image_to_base64(image_bytes):\n",
    "    \"\"\"Convert image bytes to base64 string for API transmission\"\"\"\n",
    "    try:\n",
    "        # Convert bytes to base64 string\n",
    "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        return base64_string\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting image to base64: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configuration widgets for image generation\n",
    "print(\"üîß NIM Endpoint Configuration\")\n",
    "print(\"Configure your NIM endpoints for image generation\")\n",
    "print()\n",
    "\n",
    "# Endpoint selection dropdown\n",
    "endpoint_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Custom NIM Endpoint', 'custom')\n",
    "    ],\n",
    "    value='custom',\n",
    "    description='NIM Endpoint:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Custom endpoint input (shown when 'custom' is selected)\n",
    "custom_endpoint_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter your NIM endpoint URL (e.g., https://your-deployment.cloud.lepton.ai)',\n",
    "    description='Custom URL:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# NGC API Key input\n",
    "ngc_api_key_widget = widgets.Password(\n",
    "    value='',\n",
    "    placeholder='Enter your NGC API key (optional for public deployments)',\n",
    "    description='NGC API Key:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(endpoint_widget)\n",
    "display(custom_endpoint_widget)\n",
    "display(ngc_api_key_widget)\n",
    "\n",
    "print()\n",
    "print(\"üé® Image Generation Parameters\")\n",
    "\n",
    "# Test image display function\n",
    "def test_image_display():\n",
    "    \"\"\"Test if image display is working in Jupyter\"\"\"\n",
    "    try:\n",
    "        # Create a simple test image\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "        \n",
    "        # Create a 100x100 test image with gradient\n",
    "        test_array = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        test_array[:, :, 0] = np.linspace(0, 255, 100).reshape(1, -1)  # Red gradient\n",
    "        test_array[:, :, 1] = np.linspace(0, 255, 100).reshape(-1, 1)  # Green gradient\n",
    "        test_array[:, :, 2] = 128  # Blue constant\n",
    "        \n",
    "        test_image = PILImage.fromarray(test_array)\n",
    "        \n",
    "        # Convert to base64 for testing\n",
    "        import io, base64\n",
    "        buffer = io.BytesIO()\n",
    "        test_image.save(buffer, format='PNG')\n",
    "        test_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "        \n",
    "        print(\"üß™ Testing image display...\")\n",
    "        display_image_from_base64(test_base64, \"Test Image - Gradient Pattern\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Image display test failed: {e}\")\n",
    "\n",
    "# Uncomment the line below to test image display\n",
    "# test_image_display()\n",
    "\n",
    "# Model selection for comparison\n",
    "# Model selection - FLUX.1-dev only at this stage\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=[('FLUX.1 Dev', 'flux.1-dev')],\n",
    "    value='flux.1-dev',\n",
    "    description='Model:',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Textarea for detailed prompt input\n",
    "prompt_widget = widgets.Textarea(\n",
    "    value='A serene mountain landscape at sunset with dramatic clouds',\n",
    "    placeholder='Enter your image generation prompt (be detailed for best results)',\n",
    "    description='Prompt:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px', height='80px')\n",
    ")\n",
    "\n",
    "# Slider for controlling inference steps (quality vs speed tradeoff)\n",
    "steps_widget = widgets.IntSlider(\n",
    "    value=50,           # Balanced default\n",
    "    min=1,              # Minimum (very fast, lower quality)\n",
    "    max=100,            # Maximum (slower, higher quality)\n",
    "    step=1,\n",
    "    description='Steps:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Seed input for reproducible results\n",
    "seed_widget = widgets.IntText(\n",
    "    value=42,           # Default seed for consistency\n",
    "    description='Seed:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "display(model_selector)\n",
    "display(prompt_widget)\n",
    "display(steps_widget)\n",
    "display(seed_widget)\n",
    "\n",
    "def run_generation():\n",
    "    \"\"\"Run image generation with corrected API format and image display\"\"\"\n",
    "    \n",
    "    endpoint = endpoint_widget.value\n",
    "    if endpoint == 'custom':\n",
    "        endpoint = custom_endpoint_widget.value\n",
    "        \n",
    "    ngc_api_key = ngc_api_key_widget.value\n",
    "    prompt = prompt_widget.value\n",
    "    steps = steps_widget.value\n",
    "    seed = seed_widget.value\n",
    "    model = model_selector.value\n",
    "    \n",
    "    if not endpoint.strip():\n",
    "        print(\"‚ùå Please select or enter a NIM endpoint\")\n",
    "        return\n",
    "        \n",
    "    if not prompt.strip():\n",
    "        print(\"‚ùå Please enter a prompt\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üöÄ Generating images with {len(models)} model(s)...\")\n",
    "    print(f\"Endpoint: {endpoint}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Parameters: {steps} steps, seed {seed}\")\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    \n",
    "    results = []\n",
    "    generated_images = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"\\\\nüé® Generating with {model} via NIM...\")\n",
    "        \n",
    "        result = generate_with_nim(endpoint, ngc_api_key, model, prompt, steps, seed)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ {model}: Generated in {result['generation_time']:.2f}s\")\n",
    "            \n",
    "            # Display the generated image\n",
    "            image_title = f\"{model} - {prompt[:50]}...\"\n",
    "            pil_image = display_image_from_base64(result['image_base64'], image_title)\n",
    "            \n",
    "            if pil_image:\n",
    "                # Save image to outputs directory\n",
    "                os.makedirs('examples/outputs', exist_ok=True)\n",
    "                timestamp = int(time.time())\n",
    "                filename = f\"flux_{model}_{timestamp}.png\"\n",
    "                filepath = f\"examples/outputs/{filename}\"\n",
    "                \n",
    "                if save_image_from_base64(result['image_base64'], filepath):\n",
    "                    print(f\"üíæ Image saved: {filepath}\")\n",
    "                    result['saved_path'] = filepath\n",
    "                \n",
    "                generated_images.append({\n",
    "                    'model': model,\n",
    "                    'image': pil_image,\n",
    "                    'filepath': filepath,\n",
    "                    'generation_time': result['generation_time']\n",
    "                })\n",
    "        else:\n",
    "            print(f\"‚ùå {model}: {result['error']}\")\n",
    "    \n",
    "    # Display results summary\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"üìä Results Summary:\")\n",
    "    \n",
    "    successful_results = [r for r in results if r['success']]\n",
    "    \n",
    "    if successful_results:\n",
    "        print(f\"\\\\n‚è±Ô∏è  Generation Times:\")\n",
    "        for result in successful_results:\n",
    "            print(f\"  {result['model']}: {result['generation_time']:.2f}s\")\n",
    "            \n",
    "        fastest = min(successful_results, key=lambda x: x['generation_time'])\n",
    "        print(f\"\\\\nüèÜ Fastest: {fastest['model']} ({fastest['generation_time']:.2f}s)\")\n",
    "        \n",
    "        print(f\"\\\\nüñºÔ∏è  Generated {len(generated_images)} image(s)\")\n",
    "        \n",
    "        # Save results for analysis (without base64 data to keep file size manageable)\n",
    "        results_for_save = []\n",
    "        for r in results:\n",
    "            r_copy = r.copy()\n",
    "            if 'image_base64' in r_copy:\n",
    "                del r_copy['image_base64']  # Remove large base64 data\n",
    "            results_for_save.append(r_copy)\n",
    "        \n",
    "        with open('examples/outputs/last_comparison.json', 'w') as f:\n",
    "            json.dump({\n",
    "                'prompt': prompt,\n",
    "                'parameters': {'steps': steps, 'seed': seed},\n",
    "                'endpoint': endpoint,\n",
    "                'results': results_for_save,\n",
    "                'timestamp': time.time()\n",
    "            }, f, indent=2)\n",
    "            \n",
    "        print(\"\\\\nüíæ Results saved to examples/outputs/last_comparison.json\")\n",
    "        print(\"\\\\nüí° Check examples/outputs/ directory for generated images\")\n",
    "    else:\n",
    "        print(\"‚ùå No successful generations. Check:\")\n",
    "        print(\"  - NIM container is running (docker ps)\")\n",
    "        print(\"  - Endpoint URL is correct\")\n",
    "        print(\"  - Container health: curl http://localhost:8000/health\")\n",
    "\n",
    "# Create generation button\n",
    "generate_button = widgets.Button(\n",
    "    description='üé® Generate',\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "generate_button.on_click(lambda b: run_generation())\n",
    "display(generate_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis tools\n",
    "def analyze_performance():\n",
    "    \"\"\"Analyze performance from saved results\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open('examples/outputs/last_comparison.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        results = data['results']\n",
    "        successful = [r for r in results if r['success']]\n",
    "        \n",
    "        if not successful:\n",
    "            print(\"‚ùå No successful results to analyze. Run a comparison first.\")\n",
    "            return\n",
    "            \n",
    "        print(\"üìä Performance Analysis:\")\n",
    "        print(f\"Prompt: {data['prompt']}\")\n",
    "        print(f\"Parameters: {data['parameters']}\")\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        \n",
    "        # Create performance comparison chart\n",
    "        models = [r['model'] for r in successful]\n",
    "        times = [r['generation_time'] for r in successful]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(models, times, color=['#76b900', '#ff9500', '#0076d6'])\n",
    "        plt.title('Model Performance Comparison')\n",
    "        plt.ylabel('Generation Time (seconds)')\n",
    "        plt.xlabel('FLUX Model Variant')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, time_val in zip(bars, times):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                    f'{time_val:.2f}s', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Performance insights\n",
    "        fastest = min(successful, key=lambda x: x['generation_time'])\n",
    "        slowest = max(successful, key=lambda x: x['generation_time'])\n",
    "        \n",
    "        print(f\"\\nüèÜ Performance Insights:\")\n",
    "        print(f\"Fastest: {fastest['model']} - {fastest['generation_time']:.2f}s\")\n",
    "        print(f\"Slowest: {slowest['model']} - {slowest['generation_time']:.2f}s\")\n",
    "        \n",
    "        if len(successful) > 1:\n",
    "            speedup = slowest['generation_time'] / fastest['generation_time']\n",
    "            print(f\"Speedup: {speedup:.1f}x faster\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå No comparison data found. Run a comparison first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Analysis error: {e}\")\n",
    "\n",
    "# Analysis button\n",
    "analyze_button = widgets.Button(\n",
    "    description='üìä Analyze Performance',\n",
    "    button_style='info',\n",
    "    icon='chart-line',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "analyze_button.on_click(lambda b: analyze_performance())\n",
    "display(analyze_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image gallery viewer for generated results\n",
    "def display_image_gallery():\n",
    "    \"\"\"Display a gallery of previously generated images\"\"\"\n",
    "    \n",
    "    outputs_dir = 'examples/outputs'\n",
    "    if not os.path.exists(outputs_dir):\n",
    "        print(\"‚ùå No outputs directory found. Generate some images first!\")\n",
    "        return\n",
    "    \n",
    "    # Find all PNG files in outputs directory\n",
    "    image_files = [f for f in os.listdir(outputs_dir) if f.endswith('.png')]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"‚ùå No images found in outputs directory. Generate some images first!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üñºÔ∏è  Found {len(image_files)} generated image(s):\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Sort by modification time (newest first)\n",
    "    image_files.sort(key=lambda x: os.path.getmtime(os.path.join(outputs_dir, x)), reverse=True)\n",
    "    \n",
    "    # Display images in a grid\n",
    "    cols = 2\n",
    "    rows = (len(image_files) + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 7 * rows))\n",
    "    if rows == 1:\n",
    "        axes = [axes] if cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, filename in enumerate(image_files):\n",
    "        filepath = os.path.join(outputs_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load and display image\n",
    "            image = PILImage.open(filepath)\n",
    "            \n",
    "            # Extract info from filename (flux_model_timestamp.png)\n",
    "            parts = filename.replace('.png', '').split('_')\n",
    "            if len(parts) >= 3:\n",
    "                model = parts[1]\n",
    "                timestamp = parts[2]\n",
    "                title = f\"{model}\\\\n{filename}\"\n",
    "            else:\n",
    "                title = filename\n",
    "            \n",
    "            ax = axes[i] if len(image_files) > 1 else axes\n",
    "            # Convert PIL image to numpy array for matplotlib\n",
    "            import numpy as np\n",
    "            image_array = np.array(image)\n",
    "            ax.imshow(image_array)\n",
    "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {filename}: {e}\")\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(image_files), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show file details\n",
    "    print(\"\\\\nImage Details:\")\n",
    "    for filename in image_files[:5]:  # Show details for first 5 images\n",
    "        filepath = os.path.join(outputs_dir, filename)\n",
    "        stat = os.stat(filepath)\n",
    "        size_mb = stat.st_size / (1024 * 1024)\n",
    "        mod_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))\n",
    "        print(f\"  üìÑ {filename} - {size_mb:.1f}MB - {mod_time}\")\n",
    "    \n",
    "    if len(image_files) > 5:\n",
    "        print(f\"  ... and {len(image_files) - 5} more images\")\n",
    "\n",
    "# Image gallery button\n",
    "gallery_button = widgets.Button(\n",
    "    description='üñºÔ∏è View Image Gallery',\n",
    "    button_style='info',\n",
    "    icon='images',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "gallery_button.on_click(lambda b: display_image_gallery())\n",
    "display(gallery_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: FLUX Kontext Image Editing Studio\n",
    "\n",
    "### Background: Understanding Instruction-Based Image Editing\n",
    "\n",
    "**What is FLUX Kontext?**\n",
    "FLUX Kontext represents a paradigm shift in image editing technology:\n",
    "\n",
    "- **Instruction-Based**: Uses natural language commands instead of manual selection tools\n",
    "- **Surgical Precision**: Modifies only specified elements while preserving everything else\n",
    "- **AI-Powered**: Understands context, objects, lighting, and artistic styles\n",
    "- **Non-Destructive**: Original image remains unchanged; creates new edited versions\n",
    "\n",
    "**Traditional vs Kontext Editing:**\n",
    "\n",
    "| Traditional Photo Editing | FLUX Kontext |\n",
    "|---------------------------|--------------|\n",
    "| Manual selection tools (lasso, brush) | Natural language instructions |\n",
    "| Complex layer management | Single instruction execution |\n",
    "| Requires technical expertise | Accessible to anyone |\n",
    "| Time-intensive (hours) | Fast execution (30-60 seconds) |\n",
    "| Limited by tool capabilities | Limited by imagination |\n",
    "| Static results | Multiple interpretation possibilities |\n",
    "\n",
    "**How Kontext Works:**\n",
    "1. **Input Analysis**: AI analyzes the source image to understand composition, objects, lighting\n",
    "2. **Instruction Parsing**: Natural language processing interprets editing commands\n",
    "3. **Selective Modification**: AI identifies specific areas that need changes\n",
    "4. **Context Preservation**: Maintains lighting, perspective, and style consistency\n",
    "5. **Result Generation**: Creates edited image while preserving unspecified elements\n",
    "\n",
    "**Instruction Best Practices:**\n",
    "\n",
    "**Good Instructions:**\n",
    "- \"Change the background to a sunset sky, keep the person unchanged\"\n",
    "- \"Add professional studio lighting with soft shadows, preserve everything else\"\n",
    "- \"Transform to watercolor painting style, maintain the subject and composition\"\n",
    "\n",
    "**Less Effective Instructions:**\n",
    "- \"Make it better\" (too vague)\n",
    "- \"Change everything\" (defeats the purpose of surgical editing)\n",
    "- \"Add some stuff\" (unclear what to add)\n",
    "\n",
    "**Key Principles:**\n",
    "1. **Be Specific**: Clearly state what to change\n",
    "2. **Preserve Context**: Explicitly mention what to keep unchanged\n",
    "3. **Use Descriptive Language**: Include style, color, lighting details\n",
    "4. **One Change at a Time**: Avoid complex multi-step instructions\n",
    "\n",
    "**Business Applications:**\n",
    "\n",
    "**E-commerce Photography:**\n",
    "- Remove backgrounds for product catalogs\n",
    "- Add lifestyle settings to product shots\n",
    "- Enhance colors and lighting for better appeal\n",
    "- Create multiple variants for A/B testing\n",
    "\n",
    "**Professional Photography:**\n",
    "- Fix lighting issues without reshooting\n",
    "- Change backgrounds for different contexts\n",
    "- Enhance colors and contrast\n",
    "- Remove unwanted objects\n",
    "\n",
    "**Marketing and Creative:**\n",
    "- Adapt images for different campaigns\n",
    "- Change seasonal elements (summer to winter)\n",
    "- Apply brand-consistent styling\n",
    "- Create variations for different platforms\n",
    "\n",
    "**What the Kontext Code Does:**\n",
    "- **Image Upload Handling**: Manages file uploads and base64 conversion\n",
    "- **Template System**: Provides proven editing instructions\n",
    "- **API Integration**: Sends images + instructions to Kontext NIM\n",
    "- **Before/After Display**: Shows original and edited images side-by-side\n",
    "- **Batch Processing**: Handles multiple editing operations\n",
    "- **Metadata Tracking**: Saves editing history and parameters\n",
    "\n",
    "**API Payload Format for Kontext:**\n",
    "```json\n",
    "{\n",
    "  \"prompt\": \"Your editing instruction\",\n",
    "  \"image\": \"data:image/png;base64,YOUR_BASE64_STRING\",\n",
    "  \"seed\": 42,\n",
    "  \"steps\": 50\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Differences from Regular FLUX:**\n",
    "- **Image Parameter**: Uses `\"image\"` field with data URI format (`data:image/png;base64,...`)\n",
    "- **No Mode Parameter**: Kontext doesn't use the `\"mode\"` field\n",
    "- **Instruction Parameter**: Uses `prompt` field for editing instructions\n",
    "- **Base64 Format**: Image must be provided as base64-encoded data URI string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLUX Kontext NIM Deployment\n",
    "# Deploy FLUX Kontext for instruction-based image editing\n",
    "\n",
    "print(\"üöÄ FLUX Kontext NIM Deployment\")\n",
    "print(\"Deploy FLUX Kontext for instruction-based image editing\")\n",
    "print(\"‚è±Ô∏è  Expected time: 3-5 minutes\")\n",
    "print(\"üìä Resource requirements: 1 GPU per endpoint\")\n",
    "print()\n",
    "print(\"üéØ DEPLOYING FLUX KONTEXT:\")\n",
    "print(\"  ‚Ä¢ Instruction-Based Image Editing: Edit images with natural language\")\n",
    "print(\"  ‚Ä¢ High Quality Results: Surgical precision modifications\")\n",
    "print(\"  ‚Ä¢ Non-Destructive: Preserves original image quality\")\n",
    "print()\n",
    "print(\"‚ö†Ô∏è  PREREQUISITE: Complete Lepton CLI authentication first!\")\n",
    "print()\n",
    "\n",
    "# Kontext deployment configuration\n",
    "kontext_endpoint_name_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Leave empty for auto-generated name (flux-kontext)',\n",
    "    description='Endpoint Name:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Reuse the same configuration widgets from FLUX.1-dev deployment\n",
    "print(\"üìã SETUP REQUIREMENTS:\")\n",
    "print(\"1. üîë Hugging Face Token: REQUIRED for all FLUX NIMs (reuse from FLUX.1-dev setup)\")\n",
    "print(\"2. üè¢ Node Group: Your specific node group name\")\n",
    "print(\"3. üîê Image Pull Secrets: From Lepton Settings ‚Üí Registries\")\n",
    "print()\n",
    "\n",
    "display(kontext_endpoint_name_widget)\n",
    "\n",
    "# Kontext deployment function\n",
    "def deploy_kontext_nim():\n",
    "    \"\"\"Deploy FLUX Kontext NIM endpoint\"\"\"\n",
    "    \n",
    "    # Get configuration from the FLUX.1-dev deployment widgets (reuse them)\n",
    "    node_group = node_group_input.value.strip() if 'node_group_input' in globals() else 'tme-nebius-h200-01'\n",
    "    hf_token = hf_token_input.value.strip() if 'hf_token_input' in globals() else ''\n",
    "    image_pull_secrets = image_pull_secrets_input.value.strip() if 'image_pull_secrets_input' in globals() else 'roclark-ngc'\n",
    "    \n",
    "    endpoint_name = kontext_endpoint_name_widget.value.strip()\n",
    "    if not endpoint_name:\n",
    "        endpoint_name = \"flux-kontext\"\n",
    "    else:\n",
    "        # Sanitize user-provided endpoint name\n",
    "        endpoint_name = endpoint_name.replace('.', '-').replace('_', '-').lower()\n",
    "    \n",
    "    model = 'flux.1-kontext-dev'\n",
    "    resource_type = 'gpu.1xh200'  # Use H200 for Kontext\n",
    "    \n",
    "    with kontext_deployment_output:\n",
    "        kontext_deployment_output.clear_output(wait=True)\n",
    "        \n",
    "        print(\"üîç FLUX Kontext Deployment\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Deploying FLUX Kontext for instruction-based image editing\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"üé® Deploying: {model}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Check if CLI is available\n",
    "        lepton_cmd = os.environ.get('LEPTON_CMD', '')\n",
    "        if not lepton_cmd:\n",
    "            print(\"‚ùå No working CLI command available\")\n",
    "            print(\"üìã Please complete the Lepton CLI setup first\")\n",
    "            return\n",
    "        \n",
    "        # Try deployment\n",
    "        has_deployment_create = True  # Assume CLI is working\n",
    "        \n",
    "        if has_deployment_create:\n",
    "            print(\"üöÄ Attempting lep deployment create...\")\n",
    "            create_success, create_result = try_deployment_create(model, endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "            \n",
    "            if create_success:\n",
    "                print(\"‚úÖ FLUX Kontext deployment successful!\")\n",
    "                print(f\"üìã Result: {create_result}\")\n",
    "                print()\n",
    "                print(\"üéâ FLUX Kontext is now ready for image editing!\")\n",
    "                print(\"üìù You can now use the image editing tools below.\")\n",
    "            else:\n",
    "                print(f\"‚ùå Deployment failed: {create_result}\")\n",
    "                print()\n",
    "                print(\"üí° Common issues with FLUX Kontext:\")\n",
    "                print(\"  ‚Ä¢ HF Token required: Ensure you have a valid Hugging Face token\")\n",
    "                print(\"  ‚Ä¢ PERSISTENT RATE LIMITS: HF is aggressively rate limiting FLUX Kontext\")\n",
    "                print(\"    - Try waiting 24-48 hours before attempting again\")\n",
    "                print(\"    - Consider using a different HF account/token\")\n",
    "                print(\"    - Try deploying during off-peak hours (early morning)\")\n",
    "                print(\"  ‚Ä¢ Resource limits: Check your Lepton GPU quota\")\n",
    "                print(\"  ‚Ä¢ Alternative: Use FLUX.1-dev for now (works reliably)\")\n",
    "                print()\n",
    "                print(\"üîÑ Manual deployment guide:\")\n",
    "                generate_corrected_deployment_guide(model, endpoint_name, resource_type, node_group, hf_token, image_pull_secrets)\n",
    "\n",
    "# Kontext deployment button and output\n",
    "kontext_deploy_button = widgets.Button(\n",
    "    description='üöÄ Deploy FLUX Kontext',\n",
    "    button_style='warning',  # Orange color to distinguish from FLUX.1-dev\n",
    "    icon='rocket',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "kontext_deployment_output = widgets.Output()\n",
    "\n",
    "kontext_deploy_button.on_click(lambda b: deploy_kontext_nim())\n",
    "display(kontext_deploy_button)\n",
    "display(kontext_deployment_output)\n",
    "\n",
    "print()\n",
    "print(\"üí° After successful deployment:\")\n",
    "print(\"  ‚Ä¢ Wait 2-3 minutes for the endpoint to become ready\")\n",
    "print(\"  ‚Ä¢ Update the endpoint URL in the image editing section below\")\n",
    "print(\"  ‚Ä¢ Start editing images with natural language instructions!\")\n",
    "print()\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FLUX Kontext editing infrastructure\n",
    "def kontext_edit(image_base64, instruction, endpoint, ngc_api_key):\n",
    "    \"\"\"Generate edited image using FLUX Kontext with instruction-based editing\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"prompt\": instruction,\n",
    "        \"image\": f\"data:image/png;base64,{image_base64}\",  # Correct format: 'image' parameter with data URI\n",
    "        \"seed\": np.random.randint(0, 1000000),\n",
    "        \"steps\": 50\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        nim_endpoint = endpoint.rstrip('/') + '/v1/infer'\n",
    "        response = requests.post(nim_endpoint, headers=headers, json=payload, timeout=120)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generation_time = end_time - start_time\n",
    "            \n",
    "            # Parse Kontext response\n",
    "            if 'artifacts' in result and len(result['artifacts']) > 0:\n",
    "                base64_image = result['artifacts'][0].get('base64')\n",
    "                if base64_image:\n",
    "                    return {\n",
    "                        'success': True,\n",
    "                        'image_base64': base64_image,\n",
    "                        'generation_time': generation_time,\n",
    "                        'instruction': instruction,\n",
    "                        'seed': result['artifacts'][0].get('seed', payload['seed'])\n",
    "                    }\n",
    "            \n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f\"No image artifacts in Kontext response: {result}\",\n",
    "                'instruction': instruction\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': f\"Kontext API Error: {response.status_code} - {response.text}\",\n",
    "                'instruction': instruction\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "        }\n",
    "def display_before_after(original_content, edited_base64, instruction):\n",
    "    \"\"\"Display before/after comparison of original and edited images\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Original image\n",
    "    original_img = PILImage.open(io.BytesIO(original_content))\n",
    "    ax1.imshow(original_img)\n",
    "    ax1.set_title(\"Original\", fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Edited image\n",
    "    try:\n",
    "        edited_bytes = base64.b64decode(edited_base64)\n",
    "        edited_img = PILImage.open(io.BytesIO(edited_bytes))\n",
    "        ax2.imshow(edited_img)\n",
    "        ax2.set_title(f\"Edited: {instruction[:40]}{'...' if len(instruction) > 40 else ''}\", \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return edited_img\n",
    "    except Exception as e:\n",
    "        ax2.text(0.5, 0.5, f\"Error displaying edited image: {e}\", \n",
    "                ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ FLUX Kontext editing infrastructure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Photo Editor Studio\n",
    "\n",
    "Upload any photo and apply instant AI-powered edits with simple instructions. FLUX Kontext understands natural language commands and surgically modifies only what you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Photo Editor Studio\n",
    "print(\"üì∏ Interactive Photo Editor Studio\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# FLUX Kontext Endpoint Configuration\n",
    "print(\"üé® FLUX Kontext Endpoint Configuration\")\n",
    "print(\"Configure your FLUX Kontext endpoint for image editing\")\n",
    "print()\n",
    "\n",
    "# Kontext endpoint selection dropdown\n",
    "kontext_endpoint_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Custom Kontext Endpoint', 'custom')\n",
    "    ],\n",
    "    value='custom',\n",
    "    description='Kontext Endpoint:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Custom Kontext endpoint input\n",
    "custom_kontext_endpoint_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter your FLUX Kontext endpoint URL (e.g., https://your-kontext-deployment.cloud.lepton.ai)',\n",
    "    description='Custom Kontext URL:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Kontext NGC API key (can reuse the same one)\n",
    "kontext_ngc_api_key_widget = widgets.Password(\n",
    "    placeholder='Enter your NGC API key (same as regular FLUX)',\n",
    "    description='NGC API Key:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(kontext_endpoint_widget)\n",
    "display(custom_kontext_endpoint_widget)\n",
    "display(kontext_ngc_api_key_widget)\n",
    "\n",
    "print()\n",
    "print(\"üí° Note: FLUX Kontext requires a separate endpoint from regular FLUX.1-dev\")\n",
    "print(\"üöÄ Deploy FLUX Kontext using the deployment cell above if needed\")\n",
    "print()\n",
    "\n",
    "# File upload widget\n",
    "photo_upload = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False,\n",
    "    description='üì∏ Upload Photo',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Quick edit templates with proven instructions\n",
    "edit_templates = {\n",
    "    \"üé® Artistic Style\": \"Transform to watercolor painting style, keep the subject and composition unchanged\",\n",
    "    \"üåÖ Change Background\": \"Change the background to a beautiful sunset sky, keep the subject in exact same position\",\n",
    "    \"üí° Studio Lighting\": \"Add professional studio lighting with soft shadows, keep everything else unchanged\",\n",
    "    \"üñºÔ∏è Remove Background\": \"Remove the background completely, keep the subject unchanged\",\n",
    "    \"‚ú® Enhance Colors\": \"Enhance colors and contrast to look more vibrant, keep composition unchanged\",\n",
    "    \"üåü Make Premium\": \"Make the image look more premium and professional, keep the subject unchanged\"\n",
    "}\n",
    "\n",
    "# Create template buttons\n",
    "template_buttons = []\n",
    "for name, instruction in edit_templates.items():\n",
    "    button = widgets.Button(\n",
    "        description=name,\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px', margin='2px'),\n",
    "        tooltip=instruction\n",
    "    )\n",
    "    template_buttons.append(button)\n",
    "\n",
    "# Arrange buttons in grid\n",
    "button_grid = widgets.GridBox(\n",
    "    template_buttons,\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        grid_template_columns='repeat(3, 200px)',\n",
    "        grid_gap='5px'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Custom instruction input\n",
    "custom_instruction = widgets.Textarea(\n",
    "    placeholder='Enter your custom editing instruction (e.g., \"Add glasses to the person, keep everything else unchanged\")',\n",
    "    description='Custom Edit:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px', height='80px')\n",
    ")\n",
    "\n",
    "# Custom edit button\n",
    "custom_button = widgets.Button(\n",
    "    description='‚ú® Apply Custom Edit',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(photo_upload)\n",
    "\n",
    "# Debug function to test image upload\n",
    "def test_image_upload():\n",
    "    if photo_upload.value:\n",
    "        print(f\"‚úÖ Image uploaded successfully!\")\n",
    "        print(f\"   üìÅ Filename: {list(photo_upload.value.keys())[0]}\")\n",
    "        print(f\"   üìè File size: {len(list(photo_upload.value.values())[0]['content'])} bytes\")\n",
    "        \n",
    "        # Try to decode and display basic info\n",
    "        try:\n",
    "            import base64\n",
    "            image_data = list(photo_upload.value.values())[0]['content']\n",
    "            base64_data = base64.b64encode(image_data).decode('utf-8')\n",
    "            print(f\"   üîç Base64 length: {len(base64_data)} characters\")\n",
    "            print(f\"   ‚úÖ Image ready for processing\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing image: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå No image uploaded yet\")\n",
    "        print(\"üí° Please select an image file using the upload button above\")\n",
    "\n",
    "# Test button\n",
    "test_upload_button = widgets.Button(\n",
    "    description='üîç Test Upload',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "test_upload_button.on_click(lambda b: test_image_upload())\n",
    "display(test_upload_button)\n",
    "\n",
    "print(\"\\nüéØ Quick Edit Templates:\")\n",
    "display(button_grid)\n",
    "print(\"\\n‚úèÔ∏è Custom Instructions:\")\n",
    "display(custom_instruction)\n",
    "display(custom_button)\n",
    "\n",
    "# Processing function\n",
    "def process_photo_edit(instruction):\n",
    "    \"\"\"Process photo editing with given instruction\"\"\"\n",
    "    \n",
    "    # Check if photo is uploaded\n",
    "    if not photo_upload.value:\n",
    "        print(\"‚ùå Please upload a photo first!\")\n",
    "        return\n",
    "    \n",
    "    # Get current KONTEXT endpoint configuration (separate from regular FLUX)\n",
    "    endpoint = kontext_endpoint_widget.value\n",
    "    if endpoint == 'custom':\n",
    "        endpoint = custom_kontext_endpoint_widget.value\n",
    "    ngc_api_key = kontext_ngc_api_key_widget.value\n",
    "    \n",
    "    if not endpoint.strip():\n",
    "        print(\"‚ùå Please configure NIM endpoint first!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\\\nüîÑ Processing edit: {instruction[:60]}{'...' if len(instruction) > 60 else ''}\")\n",
    "    print(\"‚è≥ This may take 30-60 seconds...\")\n",
    "    \n",
    "    try:\n",
    "        # Get uploaded file content\n",
    "        uploaded_file = photo_upload.value[0]\n",
    "        file_content = uploaded_file['content']\n",
    "        \n",
    "        # Convert to base64\n",
    "        image_base64 = image_to_base64(file_content)\n",
    "        \n",
    "        # Call FLUX Kontext\n",
    "        result = kontext_edit(image_base64, instruction, endpoint, ngc_api_key)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ Edit completed in {result['generation_time']:.2f}s\")\n",
    "            \n",
    "            # Display before/after comparison\n",
    "            edited_img = display_before_after(file_content, result['image_base64'], instruction)\n",
    "            \n",
    "            if edited_img:\n",
    "                # Save edited image\n",
    "                os.makedirs('examples/outputs', exist_ok=True)\n",
    "                timestamp = int(time.time())\n",
    "                filename = f\"kontext_edit_{timestamp}.png\"\n",
    "                filepath = f\"examples/outputs/{filename}\"\n",
    "                \n",
    "                # Save image\n",
    "                edited_bytes = base64.b64decode(result['image_base64'])\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(edited_bytes)\n",
    "                \n",
    "                print(f\"üíæ Edited image saved: {filepath}\")\n",
    "                \n",
    "                # Save edit metadata\n",
    "                metadata = {\n",
    "                    'instruction': instruction,\n",
    "                    'generation_time': result['generation_time'],\n",
    "                    'seed': result['seed'],\n",
    "                    'timestamp': timestamp,\n",
    "                    'original_filename': uploaded_file['name']\n",
    "                }\n",
    "                \n",
    "                metadata_path = f\"examples/outputs/kontext_edit_{timestamp}_metadata.json\"\n",
    "                with open(metadata_path, 'w') as f:\n",
    "                    json.dump(metadata, f, indent=2)\n",
    "                \n",
    "                print(\"üìù Edit metadata saved for future reference\")\n",
    "        else:\n",
    "            print(f\"‚ùå Edit failed: {result['error']}\")\n",
    "            print(\"üí° Try:\")\n",
    "            print(\"  - Check NIM container is running: docker ps\")\n",
    "            print(\"  - Verify endpoint URL\")\n",
    "            print(\"  - Use more specific instructions\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing edit: {str(e)}\")\n",
    "\n",
    "# Bind template buttons to processing function\n",
    "for i, (name, instruction) in enumerate(edit_templates.items()):\n",
    "    def make_handler(inst):\n",
    "        return lambda b: process_photo_edit(inst)\n",
    "    template_buttons[i].on_click(make_handler(instruction))\n",
    "\n",
    "# Bind custom instruction button\n",
    "def on_custom_edit(button):\n",
    "    instruction = custom_instruction.value.strip()\n",
    "    if instruction:\n",
    "        process_photo_edit(instruction)\n",
    "    else:\n",
    "        print(\"‚ùå Please enter a custom instruction first!\")\n",
    "\n",
    "custom_button.on_click(on_custom_edit)\n",
    "\n",
    "print(\"\\\\nüí° Tips for better results:\")\n",
    "print(\"  ‚Ä¢ Be specific about what to change and what to keep\")\n",
    "print(\"  ‚Ä¢ Use phrases like 'keep the subject unchanged'\")\n",
    "print(\"  ‚Ä¢ Try multiple variations to see different interpretations\")\n",
    "print(\"  ‚Ä¢ FLUX Kontext works best with clear, actionable instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps: FLUX Kontext Editing\n",
    "\n",
    "üéâ **You've explored advanced FLUX Kontext image editing capabilities!**\n",
    "\n",
    "### What You've Learned:\n",
    "- ‚úÖ **Instruction-based editing** with natural language commands\n",
    "- ‚úÖ **Professional photo enhancement** with surgical precision  \n",
    "- ‚úÖ **Product photography automation** for e-commerce applications\n",
    "- ‚úÖ **Before/after comparison workflows** for quality assessment\n",
    "- ‚úÖ **Batch processing techniques** for multiple variants\n",
    "\n",
    "### Key Differentiators:\n",
    "- **üéØ Surgical Editing**: FLUX Kontext modifies only what you specify\n",
    "- **üè¢ Business Applications**: Real product photography enhancement\n",
    "- **‚ö° Speed**: Professional results in 30-60 seconds\n",
    "- **üîÑ Iterative Workflow**: Build on previous edits\n",
    "- **üíæ Production Ready**: Automatic saving and metadata tracking\n",
    "\n",
    "### FLUX Kontext vs Traditional Editing:\n",
    "| Traditional Photo Editing | FLUX Kontext |\n",
    "|---------------------------|--------------|\n",
    "| Manual selection tools | Natural language instructions |\n",
    "| Hours of work | 30-60 seconds |\n",
    "| Requires expertise | Accessible to anyone |\n",
    "| Limited creativity | AI-powered imagination |\n",
    "| One result | Multiple interpretations |\n",
    "\n",
    "### Business Impact:\n",
    "- **E-commerce**: Generate multiple product shots instantly\n",
    "- **Marketing**: A/B test different visual styles\n",
    "- **Content Creation**: Rapid prototyping of visual concepts\n",
    "- **Photography**: Enhance existing shots without reshooting\n",
    "\n",
    "### Next Steps:\n",
    "- üé® **Experiment** with your own photos and products\n",
    "- üîÑ **Chain edits** for complex transformations  \n",
    "- üìä **A/B test** different styles for your use case\n",
    "- üöÄ **Deploy** your own FLUX Kontext NIM for production use\n",
    "- üìà **Scale** with automated batch processing workflows\n",
    "\n",
    "### Resources for Further Learning:\n",
    "- [NVIDIA NGC FLUX Kontext Container](https://catalog.ngc.nvidia.com/orgs/nim/teams/black-forest-labs/containers/flux.1-kontext-dev)\n",
    "- [FLUX Kontext Documentation](https://docs.nvidia.com/nim/visual-genai/latest/api/flux.1-kontext-dev.html)\n",
    "- [Black Forest Labs FLUX Models](https://huggingface.co/black-forest-labs)\n",
    "\n",
    "**üöÄ You now have hands-on experience with cutting-edge AI image editing technology that's transforming creative workflows worldwide!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy Your Own NIM Endpoint (Optional)\n",
    "\n",
    "### Background: Understanding NIM Deployment Architecture\n",
    "\n",
    "**Why Deploy Your Own NIM?**\n",
    "While local development is great for testing, production applications require scalable, cloud-based deployments:\n",
    "\n",
    "- **Scalability**: Handle multiple concurrent requests\n",
    "- **Reliability**: 99.9% uptime with redundancy and failover\n",
    "- **Performance**: Dedicated GPU resources without local limitations\n",
    "- **Security**: Isolated environments with proper authentication\n",
    "- **Cost Efficiency**: Pay-per-use instead of maintaining local hardware\n",
    "\n",
    "**Deployment Options:**\n",
    "\n",
    "**1. Lepton DevPods** (Recommended):\n",
    "- **Purpose**: Rapid cloud deployment of AI models\n",
    "- **Benefits**: Pre-configured environments, automatic scaling, simple deployment\n",
    "- **Use Case**: Production applications, API services, team collaboration\n",
    "- **Cost Model**: Pay-per-GPU-hour, automatic resource management\n",
    "\n",
    "**2. AWS/GCP/Azure**:\n",
    "- **Purpose**: Enterprise-grade cloud deployments\n",
    "- **Benefits**: Full control, enterprise compliance, existing cloud integration\n",
    "- **Use Case**: Large-scale applications, enterprise environments\n",
    "- **Cost Model**: Instance-based pricing, manual resource management\n",
    "\n",
    "**3. On-Premises Kubernetes**:\n",
    "- **Purpose**: Complete control and data sovereignty\n",
    "- **Benefits**: Full customization, no data egress, compliance control\n",
    "- **Use Case**: Regulated industries, high-security environments\n",
    "- **Cost Model**: Hardware + maintenance costs\n",
    "\n",
    "**Container Architecture:**\n",
    "```\n",
    "FLUX NIM Container\n",
    "‚îú‚îÄ‚îÄ Base Image: NVIDIA NGC optimized runtime\n",
    "‚îú‚îÄ‚îÄ Model Files: Pre-quantized FLUX weights\n",
    "‚îú‚îÄ‚îÄ TensorRT Engines: GPU-optimized inference\n",
    "‚îú‚îÄ‚îÄ API Server: REST API endpoint\n",
    "‚îú‚îÄ‚îÄ Health Checks: Container monitoring\n",
    "‚îî‚îÄ‚îÄ Configuration: Environment variables\n",
    "```\n",
    "\n",
    "**Deployment Workflow:**\n",
    "1. **Container Selection**: Choose appropriate FLUX NIM variant\n",
    "2. **Configuration Generation**: Create deployment manifests\n",
    "3. **Registry Push**: Upload container to private registry (optional)\n",
    "4. **Cloud Deployment**: Deploy to chosen cloud platform\n",
    "5. **Health Verification**: Ensure API endpoints are responding\n",
    "6. **Load Testing**: Validate performance under load\n",
    "7. **Monitoring Setup**: Configure logging and metrics\n",
    "\n",
    "**Environment Variables:**\n",
    "- **`NGC_API_KEY`**: Required for container access\n",
    "- **`NIM_PORT`**: API server port (default: 8000)\n",
    "- **`WORKSPACE`**: Working directory for files\n",
    "- **`GPU_MEMORY_FRACTION`**: GPU memory allocation\n",
    "\n",
    "**Resource Requirements:**\n",
    "\n",
    "| Model | GPU Memory | CPU Cores | System Memory | Storage |\n",
    "|-------|------------|-----------|---------------|---------|\n",
    "| FLUX.1-dev | 12GB VRAM | 4+ cores | 16GB RAM | 50GB |\n",
    "| FLUX.1-kontext-dev | 15GB VRAM | 4+ cores | 16GB RAM | 60GB |\n",
    "\n",
    "**Security Considerations:**\n",
    "- **API Key Management**: Secure storage of NGC API keys\n",
    "- **Network Security**: VPC/firewall configuration\n",
    "- **Access Control**: Authentication and authorization\n",
    "- **Data Privacy**: Image data handling and retention\n",
    "- **Compliance**: GDPR, HIPAA, SOC2 requirements\n",
    "\n",
    "**Cost Optimization:**\n",
    "- **Auto-scaling**: Scale down during low usage\n",
    "- **Spot Instances**: Use preemptible instances where possible\n",
    "- **Regional Selection**: Choose optimal regions for latency/cost\n",
    "- **Monitoring**: Track usage to optimize resource allocation\n",
    "\n",
    "**What the Deployment Code Does:**\n",
    "- **Configuration Generation**: Creates Lepton DevPod YAML manifests\n",
    "- **Container Management**: Handles Docker builds and registry operations\n",
    "- **Environment Setup**: Configures required environment variables\n",
    "- **Deployment Scripts**: Provides ready-to-run deployment commands\n",
    "- **Validation Tools**: Checks deployment health and functionality\n",
    "\n",
    "**Generated Artifacts:**\n",
    "- **`lepton_devpod.yaml`**: Kubernetes-style deployment manifest\n",
    "- **`Dockerfile.nim`**: Custom container build instructions\n",
    "- **`build_flux_nim.sh`**: Automated build script\n",
    "- **Deployment documentation**: Step-by-step deployment guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment configuration widgets\n",
    "deploy_registry_widget = widgets.Text(\n",
    "    value='nvcr.io/your-username',\n",
    "    placeholder='Enter your registry URL',\n",
    "    description='Registry:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "nim_model_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('FLUX.1 Dev', 'flux.1-dev'),\n",
    "        ('FLUX.1 Kontext Dev', 'flux.1-kontext-dev')\n",
    "    ],\n",
    "    value='flux.1-dev',\n",
    "    description='Model:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "def generate_deployment_config():\n",
    "    \"\"\"Generate Lepton deployment configuration for FLUX NIM\"\"\"\n",
    "    \n",
    "    registry = deploy_registry_widget.value\n",
    "    model = nim_model_widget.value\n",
    "    \n",
    "    # Generate Lepton DevPod config using verified container references\n",
    "    lepton_config = {\n",
    "        \"apiVersion\": \"lepton.ai/v1\",\n",
    "        \"kind\": \"DevPod\",\n",
    "        \"metadata\": {\n",
    "            \"name\": f\"flux-nim-{model}\",\n",
    "            \"labels\": {\n",
    "                \"app\": \"flux-nim\",\n",
    "                \"model\": model\n",
    "            }\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"image\": f\"nvcr.io/nim/black-forest-labs/flux.1-dev:1.1.0\" if model == 'flux.1-dev' else f\"nvcr.io/nim/black-forest-labs/flux.1-kontext-dev:1.0.0\",\n",
    "            \"resources\": {\n",
    "                \"gpu\": {\n",
    "                    \"type\": \"nvidia\",\n",
    "                    \"count\": 1\n",
    "                },\n",
    "                \"cpu\": {\n",
    "                    \"cores\": 4\n",
    "                },\n",
    "                \"memory\": \"16Gi\"\n",
    "            },\n",
    "            \"ports\": [\n",
    "                {\n",
    "                    \"name\": \"nim-api\",\n",
    "                    \"port\": 8000,\n",
    "                    \"protocol\": \"TCP\"\n",
    "                }\n",
    "            ],\n",
    "            \"env\": [\n",
    "                {\n",
    "                    \"name\": \"NGC_API_KEY\",\n",
    "                    \"value\": \"your-ngc-api-key\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save configuration\n",
    "    import yaml\n",
    "    \n",
    "    os.makedirs('configs', exist_ok=True)\n",
    "    \n",
    "    with open('configs/lepton_devpod.yaml', 'w') as f:\n",
    "        yaml.dump(lepton_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"‚úÖ Generated Lepton DevPod configuration for {model}\")\n",
    "    print(f\"üìÅ Saved to: configs/lepton_devpod.yaml\")\n",
    "    print(f\"\\nüöÄ Deploy with: lepton create --file configs/lepton_devpod.yaml\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Remember to update NGC_API_KEY in the config file!\")\n",
    "    print(f\"\\nüí° API endpoint will be: http://your-lepton-url/v1/infer\")\n",
    "\n",
    "print(\"üöÄ Optional: Deploy Your Own FLUX NIM\")\n",
    "display(deploy_registry_widget)\n",
    "display(nim_model_widget)\n",
    "\n",
    "deploy_button = widgets.Button(\n",
    "    description='Generate Deployment Config',\n",
    "    button_style='warning',\n",
    "    icon='rocket',\n",
    "    layout=widgets.Layout(width='220px', height='40px')\n",
    ")\n",
    "\n",
    "deploy_button.on_click(lambda b: generate_deployment_config())\n",
    "display(deploy_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "üéâ **You've explored NVIDIA NIMs with FLUX models!**\n",
    "\n",
    "### What You've Learned:\n",
    "- ‚úÖ How NIMs provide optimized model inference\n",
    "- ‚úÖ Performance differences between FLUX model variants\n",
    "- ‚úÖ How to integrate NIMs into your workflows\n",
    "- ‚úÖ Optional deployment patterns for your own endpoints\n",
    "\n",
    "### Key Takeaways:\n",
    "- **FLUX Schnell**: Best for rapid prototyping and iteration\n",
    "- **FLUX Dev**: Balanced quality/speed for most use cases\n",
    "- **FLUX Kontext**: Highest quality for production outputs\n",
    "- **NIMs**: Easier deployment than managing local models\n",
    "\n",
    "### Next Steps:\n",
    "- üé® Experiment with different prompts and parameters\n",
    "- üîß Deploy your own NIM endpoints for custom control\n",
    "- üìà Integrate NIMs into larger AI workflows\n",
    "- üöÄ Explore other NIMs models beyond FLUX\n",
    "\n",
    "### Resources:\n",
    "- [NVIDIA NGC Catalog](https://catalog.ngc.nvidia.com/)\n",
    "- [FLUX Model Documentation](https://github.com/black-forest-labs/flux)\n",
    "- [Lepton AI Documentation](https://docs.lepton.ai/)\n",
    "\n",
    "Happy experimenting! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
