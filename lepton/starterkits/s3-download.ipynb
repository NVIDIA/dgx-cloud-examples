{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4cab92-6213-4288-a425-ce405c28f8a4",
   "metadata": {},
   "source": [
    "# S3 Data Download into Lepton Local Storage\n",
    "\n",
    "This notebook shows how data can be downloaded from an external S3 bucket to mounted storage on a DGX Cloud Lepton Dev Pod. It makes use of a publicly available dataset for global fishery statistics purely as an example of loading a CSV dataset into a pandas DataFrame. The intent is for developers to make use of their own S3 buckets for transferring data to and from the Dev Pod.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The license and terms of use for this sample dataset can be found <a href=https://registry.opendata.aws/sau-global-fisheries-catch-data/>here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee1fa1-57ca-425e-af5f-015d5d914ee5",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "-  Image: A Rapids Notebook container image such as `nvcr.io/nvidia/rapidsai/notebooks:25.08-cuda12.9-py3.13` or later\n",
    "-  Packages: s3fs Python package installed\n",
    "-  GPU: An NVIDIA Ampere or greater class GPU for cuDF acceleration (for example, A100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5ffb5-f4a3-4783-902f-346eab98aad1",
   "metadata": {},
   "source": [
    "### Storage Mount Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ef160-5244-4c78-a928-fef4d7808229",
   "metadata": {},
   "source": [
    "Follow the instructions __[here](https://docs.nvidia.com/dgx-cloud/lepton/features/storage/)__ to setup either Node Local or Static NFS volumes in DGX Cloud Lepton. The UID/GID of the prescribed Rapids container image is 1001 (non-root, `rapids`). So, there are two options in Lepton for ensuring the storage mount is writable: \n",
    "1. Launch the Dev Pod using not the default user of `rapids` but with `root`.\n",
    "2. Create a Node Local storage mount using a world-writable location on the node such as`/tmp`. Using `/tmp` of course has the caveat that the files there may be deleted after a reboot. Thus, it's important to also use S3 to periodically store your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ef1b5-ba98-4b23-9703-5e3e4e8f2bf9",
   "metadata": {},
   "source": [
    "### Install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbed40-9056-47c1-a7c8-8d8225d4faaa",
   "metadata": {},
   "source": [
    "Make sure that we have the __[s3fs](https://s3fs.readthedocs.io/en/latest/)__ pip package installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d414eb9-d475-4df9-9ab3-d9f81838a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4cc3d-9063-4fcf-be3a-11d3192b8768",
   "metadata": {},
   "source": [
    "### Import pandas (Optionally with cuDF GPU Acceleration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931b26b-2e40-4b89-965a-5843a40d3a07",
   "metadata": {},
   "source": [
    "If we want to run the GPU accelerated version of __[pandas](https://pandas.pydata.org/docs/index.html)__, we can load the __[cuDF](https://docs.rapids.ai/api/cudf/stable/)__ extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec781df5-4119-430e-ad5a-33f799ebb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ecb78-f952-429f-ab5c-f31acf1d4dc2",
   "metadata": {},
   "source": [
    "Import pandas in its own cell to make sure the previous load extension step was completed by the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43b116-ada7-4b13-a63d-fa81584a8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef1b56-3043-45cc-a3e5-307072bd4989",
   "metadata": {},
   "source": [
    "### Anonymous S3 Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a457b-a700-4bb4-b3f9-8868c367ac6b",
   "metadata": {},
   "source": [
    "Import the s3fs package and then as an example load a publicly available S3 dataset for yearly fishery statistics from around the globe. No credentials, access keys, secrets, or account are required in this case (anonymous access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ead68-b914-4957-a0bc-0281ceba49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76f033-1ec3-4304-93a1-19b6db3cea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = '/tmp/rfmo_12.csv'\n",
    "bucket_path = 's3://fisheries-catch-data/global-catch-data/csv/rfmo_12.csv'\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feedb3dd-c753-4846-943a-2be61231187b",
   "metadata": {},
   "source": [
    "### Options for Connecting to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3b7dc-8858-4b4b-8e5b-6968cf579475",
   "metadata": {},
   "source": [
    "If you need to access a private S3 bucket then there are keyword arguments for the key and secret to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11956f0b-5cfe-490d-abab-e4782ab5a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = s3fs.S3FileSystem(\n",
    "#      key='YOUR_ACCESS_KEY...',\n",
    "#      secret='YOUR_ACCESS_SECRET...'\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffb577-a034-4e0a-836e-1f407acd7cac",
   "metadata": {},
   "source": [
    "s3fs can also detect and use appropriate environment variables if they have been set for the key and secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19079174-9e7b-4cd6-a346-fd442d4b4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export FSSPEC_S3_KEY='YOUR_ACCESS_KEY...'\n",
    "# export FSSPEC_S3_SECRET='YOUR_ACCESS_SECRET...'\n",
    "# s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51306d-0042-4d1d-8d59-67300781e3d7",
   "metadata": {},
   "source": [
    "Credentials can also be detected and used by the underlying boto credential helper from client_kwargs, environment variables, config files, or an EC2 IAM server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6466c8-4c00-4555-bcd4-5aa0237074c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = s3fs.S3FileSystem(anon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2871b-894a-411a-9e58-9cb2df0a84a4",
   "metadata": {},
   "source": [
    "Finally, s3fs is compatible with non-AWS object storage such as MinIO. In this case, we would specify the URL of the MinIO endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83037fa3-93c0-4457-bf56-729b0e5915b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = s3fs.S3FileSystem(\n",
    "#      endpoint_url='https://non.aws.such.as.minio...'\n",
    "#   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da116d-e4c0-49a2-8363-1a18f5afd8c5",
   "metadata": {},
   "source": [
    "### Download a Dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02718c0-8de3-4c1a-b6cd-de9e3118c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download(bucket_path, local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed9ad9-a502-4b60-9eab-3ff92d8e91a0",
   "metadata": {},
   "source": [
    "Perform a cursory check that we have download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5530191-b948-4505-9d2b-c68b50e5f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /tmp/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06983d00-0ed9-4376-a3b2-daa6c8550ab1",
   "metadata": {},
   "source": [
    "### Load the Dataset into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabdb35-8077-41a4-8901-dcfd2af180e7",
   "metadata": {},
   "source": [
    "Read the downloaded CSV file into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8f79a-eff3-42cf-85b5-b2b585079757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426a237-05b1-42c8-b2b3-85936a16cb46",
   "metadata": {},
   "source": [
    "### Work with the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3825421-1335-4249-b613-15a4b96ac9c2",
   "metadata": {},
   "source": [
    "Check the number of rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af2f5-1149-415c-819e-aa8d2ad3d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f015e04c-d9df-4b24-af43-28a707ed77bd",
   "metadata": {},
   "source": [
    "Examine the original datatypes used for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef25bc-4ce3-4b26-8d1e-425d1ac417c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8e8ec-70b8-4bd2-b2d3-afa66698d038",
   "metadata": {},
   "source": [
    "Generally describe the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95193c7-f18b-4058-be81-78ea3dab0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b55757-2463-415b-8305-939af0c40f87",
   "metadata": {},
   "source": [
    "Look at the first 5 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf0090-78db-43e1-be01-824265ab9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d984b-af3b-497b-ade7-448aa0838fe1",
   "metadata": {},
   "source": [
    "Look at the last 5 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a1b30-6f98-4e83-9d0e-f7362f8ac7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0c45c-11eb-40b5-94af-157d1c1dce72",
   "metadata": {},
   "source": [
    "Count the top 15 different instances of fishing gear in the dataset. Profile the GPU usage (which may be minimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaff38c-9316-40c3-b1ff-c228d887b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "df[\"gear_name\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5939dc-5922-4eb9-a131-9eb621b0ef34",
   "metadata": {},
   "source": [
    "Convert some of the columns from object to numeric or date types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b6701-bc88-4e3e-9919-a21656d33ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['year'])\n",
    "df['catch_sum'] = pd.to_numeric(df['catch_sum'])\n",
    "df['real_value'] = pd.to_numeric(df['real_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b760b9-fb26-4f4a-be5b-e07cd45e29d6",
   "metadata": {},
   "source": [
    "Check the datatypes again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7b36b-7137-403f-8b5e-beb9123699e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2825bc-5799-4a83-bbb2-ebd181a13bfb",
   "metadata": {},
   "source": [
    "Collect the last 5 years of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089cb7f-7cc3-4e8c-9756-707a977ffbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df['year'].unique()[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a7cd8-0641-4710-a899-0de90c0b49cf",
   "metadata": {},
   "source": [
    "Create a new DataFrame from the top 15 countries in the dataset with the largest total catch in metric tonnes between 2014 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92455a92-3dbd-4ac6-b339-d77ec9240b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fisheries_by_catch = df[(df['year'] >= years[0]) & (df['year'] <= years[4])].groupby(['fishing_entity'], as_index = False)[['catch_sum']].sum().copy().sort_values(by='catch_sum',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d913a2b-b5e4-4434-b0e7-59f0505a475c",
   "metadata": {},
   "source": [
    "Plot the result as a horizontal bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168ff26-07d4-4ff4-9cf4-d738018fb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec113211-794c-4605-850f-ea0deb25898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'green', 'blue', 'purple', 'orange','yellow']\n",
    "top_fisheries_by_catch.plot(x='fishing_entity',y='catch_sum',kind='barh',color=colors,legend=False)\n",
    "plt.title('Top 15 Fishing Catch by Country/Region 2014-2018')\n",
    "plt.xlabel('Metric Tonnes')\n",
    "plt.ylabel('Countries/Regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646c443-6748-40a7-aa85-a11ef09b99f5",
   "metadata": {},
   "source": [
    "This completes the notebook example."
   ]
  }
 ],
 "metadata": {
  "container_image": "nvcr.io/nvidia/rapidsai/notebooks:25.08-cuda12.9-py3.13",
  "description": "This Starter Kit demonstrates moving data into DGX Cloud Lepton.",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "title": "S3 Data Download into Lepton Local Storage"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
