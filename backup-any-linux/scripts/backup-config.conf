# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# S3 Backup System Configuration File - Version 2.0
# This file contains ONLY implemented and actively used configuration settings
# 
# IMPORTANT: Keep this file secure as it may contain sensitive information
# In production, consider using environment variables or IAM roles instead of
# storing credentials in this file.

#######################################################################
# S3 Backend Configuration (REQUIRED)
#######################################################################

# S3 bucket name (REQUIRED)
# The AWS S3 bucket where backups will be stored
S3_BUCKET="My_bucket_name"

# S3 prefix/path within the bucket (Reccomended)
# This creates a folder structure in your S3 bucket for organization
# Example: "company-backups" creates s3://bucket/company-backups/
S3_PREFIX="my_projects_backup_folder"

# AWS Region (REQUIRED)
# The AWS region where your S3 bucket is located
# Examples: us-east-1, eu-west-2, ap-south-1
AWS_REGION="eu-west-2"

# AWS Profile to use (OPTIONAL) - Not tested
# Leave commented to use default profile or IAM instance role
# Uncomment to use a specific AWS CLI profile:
# AWS_PROFILE="backup-profile"

#######################################################################
# AWS Authentication (Choose ONE method)
#######################################################################


# Method 1: Environment Variables (RECOMMENDED for containers)
# Set these environment variables instead of hardcoding:
# export AWS_ACCESS_KEY_ID="your-access-key"
# export AWS_SECRET_ACCESS_KEY="your-secret-key"
# export AWS_SESSION_TOKEN="your-session-token"  # Only if using temporary credentials

# Method 2: IAM Role (BEST for production) - not tested
# Attach an IAM role to your EC2/ECS/Kubernetes workload
# No additional configuration needed - automatically detected

#######################################################################
# Operational Configuration
#######################################################################

# Dry-run mode (OPTIONAL) 
# When set to "true", simulates all operations without making changes
# Provides detailed analysis of what would be done including:
# - Files that would be uploaded/downloaded/deleted
# - MD5 checksums that would be calculated
# - Data transfer size estimates
# - State file changes that would be made
#
# Useful for:
# - Testing configuration changes safely
# - Capacity planning and impact analysis
# - Validating backup logic before production runs
#
# Can be overridden with --dry-run command line flag or DRY_RUN environment variable
# Values: "true" or "false"
# Default: false
DRY_RUN=false

# Mount directory (OPTIONAL)
# Override the default /mount directory to specify where your data is located
# This is the root directory that will be scanned for backup trigger files
MOUNT_DIR="/mount/"

#######################################################################
# Deleted File Management
#######################################################################

# Retention time for deleted files in yesterday_state before permanent removal
# Deleted files are prefixed with 'deleted_' and automatically cleaned up after this period
#
# Format options:
#   DD:HH:MM  - Days:Hours:Minutes (e.g., "01:02:30" = 1 day, 2 hours, 30 minutes)  
#   INTEGER   - Legacy format, days only (e.g., "30" = 30 days)
#
# Examples:
#   "00:00:01" = 1 minute (for testing)
#   "00:10:00" = 10 hours
#   "01:00:00" = 1 day
#   "07:12:30" = 7 days, 12 hours, 30 minutes
#   "30:00:00" = 30 days
#   "30"       = 30 days (legacy format)
#
# Set to 0 or "00:00:00" to disable automatic cleanup of deleted files
# Default: 30 days
DELETED_FILE_RETENTION=30:00:00

# Retention time for old file versions (modified files) before cleanup
# Format: DD:HH:MM (days:hours:minutes)
# Example: 90:00:00 = 90 days
#
# NOTE: With the versions_ prefix strategy, old versions of modified files
# are stored separately from truly deleted files:
# - yesterday_state/deleted_*  = Truly deleted files (DELETED_FILE_RETENTION)
# - yesterday_state/versions_* = Old versions of modified files (VERSION_RETENTION)
#
# This feature is IMPLEMENTED but DISABLED by default for safety.
# Typically, you want to keep versions LONGER than deletions for recovery purposes.
# Recommended: 90:00:00 (90 days = 3x the deletion retention) for production.
#
# Set to 0 or "00:00:00" to disable automatic cleanup of versions (keep indefinitely)
# Default: 0 (disabled - versions kept indefinitely)
VERSION_RETENTION=0

#######################################################################
# Backup Strategy Configuration
#######################################################################

# Directory path preservation: "true" or "false"
# Controls how directory paths are stored in S3
# - true: Preserve full directory path structure (RECOMMENDED)
#   Example: /mount/folder1/folder2/data/ → s3://bucket/prefix/folder1/folder2/data/
# - false: Use only directory name (not recommended)
#   Example: /mount/folder1/folder2/data/ → s3://bucket/prefix/data/
# Default: true
PRESERVE_DIRECTORY_PATHS="true"

# Checksum algorithm for change detection: "md5", "sha256", or "mtime"
# - md5: Fast, good for most use cases (RECOMMENDED)
# - sha256: More secure, slower
# - mtime: Uses file modification time (fastest, but less reliable)
# Default: md5
CHECKSUM_ALGORITHM="md5"

# Integrity checking mode (PERFORMANCE vs SECURITY trade-off)
# Controls how checksums are calculated for change detection
# - fast: Trust mtime+size for unchanged files (99% performance gain, ~1% edge case risk)
# - strict: Always calculate fresh checksums (100% integrity, slower performance)
# - hybrid: Fast for most files, strict for critical extensions (balanced approach)
# Default: fast
INTEGRITY_MODE="fast"

# For hybrid mode: file extensions that always get strict checking
# Comma-separated list of extensions (include the dot: .db,.sql,.config)
# Only used when INTEGRITY_MODE="hybrid"
# Default: .db,.sql,.config,.json,.xml,.key,.crt,.pem
STRICT_EXTENSIONS=".db,.sql,.config,.json,.xml,.key,.crt,.pem"

#######################################################################
# Audit System Configuration
#######################################################################

# Enable three-file audit system for complete deletion tracking
# When enabled, maintains state files that mirror S3 structure:
# - current-backup-state.json     (mirrors current_state/ in S3)
# - yesterday-backup-state.json   (mirrors yesterday_state/ in S3) 
# - permanent-deletions-history.json (complete audit trail)
#
# Benefits:
# - Complete deletion audit trail with timestamps and metadata
# - Track retention policy changes and admin behavior  
# - Dual size tracking (original size vs size at deletion)
# - Perfect S3 structure mirroring for easy recovery
# - Compliance-friendly forensic capabilities
#
# Values: "true" or "false"
# Default: true
AUDIT_SYSTEM_ENABLED="true"

#######################################################################
# Forced Alignment Configuration
#######################################################################

# Enable forced alignment mode to reconcile filesystem vs S3 state
# When enabled, performs a one-time alignment operation to:
# - Compare current filesystem state with S3 current_state contents
# - Identify orphaned S3 objects (files/dirs no longer on filesystem)
# - Move orphaned objects to yesterday_state with deleted_ prefix
# - Track directory backup mode changes (shallow<->deep transitions)
# - Generate alignment report for user review
#
# IMPORTANT: This is a one-time operation mode. The script will:
# 1. Perform alignment operations atomically 
# 2. Reset FORCE_ALIGNMENT_MODE to "false" after completion
# 3. Exit after alignment (no regular backup operations)
#
# Use cases:
# - After major directory reorganizations or deletions
# - When switching backup modes for large directory trees
# - Periodic cleanup of orphaned S3 objects
# - Disaster recovery and state synchronization
#
# Can be overridden with --force-alignment command line flag
# Values: "true" or "false"
# Default: false
FORCE_ALIGNMENT_MODE="false"

# Alignment history retention (number of alignment operations to keep)
# Controls how many historical forced alignment operations are stored
# in the directory-state.json file for operational tracking and audit
#
# Each alignment operation record includes:
# - Timestamp and duration
# - Objects moved and size statistics  
# - Size distribution breakdown
# - Performance metrics
#
# Higher values provide more historical data but increase JSON file size
# Recommended: 50-100 for operational environments, 20-30 for development
#
# Values: Any positive integer
# Default: 50
ALIGNMENT_HISTORY_RETENTION="50"

#######################################################################
# Filesystem Scan Management
#######################################################################

# Filesystem scan refresh threshold (hours) - Was active in prior version, may implement in future. 
# Controls how often the filesystem directory map is refreshed
# Lower values = more frequent scans = more current but slower performance
# Higher values = less frequent scans = faster but potentially stale directory info
#
# Critical scenarios that benefit from lower values:
# - Frequent backup trigger file changes (backupalldirs.txt / backupthisdir.txt)
# - Dynamic directory structure changes
# - Development/testing environments
#
# Production environments with stable directory structures can use higher values
#
# Recommended values:
#   Development/Testing: 1-2 hours
#   Production stable:   12-24 hours
#   Emergency scenarios: 0.25 hours (15 minutes)
#
# Values: Decimal hours (e.g., 1.5 = 1 hour 30 minutes)
# Default: 2
# FILESYSTEM_SCAN_REFRESH_HOURS="2"

# Force filesystem scan refresh flag - Was active in prior version, may implement in future. 
# When set to "true", forces a complete filesystem scan on every backup run
# regardless of the FILESYSTEM_SCAN_REFRESH_HOURS threshold
#
# WARNING: This bypasses performance optimization and will slow down backups
# Only use temporarily for debugging or when directory structure changes frequently
#
# Use cases:
# - Debugging filesystem scanning issues
# - After major directory restructuring
# - Ensuring absolutely current directory mapping
# - Testing scenarios with rapid backup trigger changes
#
# Values: "true" or "false"
# Default: false
# FORCE_FILESYSTEM_SCAN_REFRESH="false"

#######################################################################
# S3 Reporting Configuration
#######################################################################

# Generate detailed S3 report after backup completion (OPTIONAL)
# When enabled, creates a comprehensive report with rich metadata about all S3 objects
# 
# Report includes:
# - Complete file listing with sizes, timestamps, storage classes
# - Backup prefix categorization (current_state, yesterday_state)
# - Scan statistics and performance metrics
# - Directory structures and file extensions
#
# Output: ../state/s3/s3-report.json
#
# Performance impact:
# - Adds ~5-7 seconds at END of backup (after all operations complete)
# - Performs one additional S3 scan for accuracy
# - Does NOT regenerate s3-cache.json (uses --report-only flag)
#
# Use cases:
# - Auditing and compliance reporting
# - Storage analysis and capacity planning
# - Debugging and troubleshooting
# - Integration with external monitoring tools
#
# Values: "true" or "false"
# Default: false
DETAILED_S3_REPORT=false

#######################################################################
# Logging Configuration
#######################################################################

# Log level: "DEBUG", "INFO", "WARN", "ERROR"
# Controls the verbosity of log output
# - DEBUG: Detailed information for troubleshooting (very verbose)
# - INFO: General information about backup progress (RECOMMENDED)
# - WARN: Warning messages only
# - ERROR: Error messages only
#
# Can be overridden with LOG_LEVEL environment variable
# Default: INFO
LOG_LEVEL="INFO"

#######################################################################
# Environment Variable Override Examples
#######################################################################
# You can override these settings using environment variables:
#
# # Use different S3 bucket for testing
# S3_BUCKET="test-backup-bucket" LOG_LEVEL="DEBUG" ./backup.sh
#
# # Enable dry-run mode
# DRY_RUN=true ./backup.sh
#
# # Docker container example
# docker run -e S3_BUCKET=my-backup-bucket \
#            -e AWS_REGION=us-west-2 \
#            -e LOG_LEVEL=DEBUG \
#            -v /host/mount:/mount:ro \
#            your-backup-container
#
# The script will use environment variables if they exist, otherwise it will
# fall back to the values in this configuration file